{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35c58e4e-9226-4d24-ae10-b84c5cc05ce5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15a31da-c6c3-427d-a070-afdc48a01305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f0f6378-5bc3-477d-bfd3-a08a9123b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f309cc84-f338-409f-b1a3-6ac36b945622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39328b9-9fa8-4937-9a53-905ea59276c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59041be7-8d30-4981-a3da-e5d090a32339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72e92418-e8e7-4baa-882f-92b87f2c68ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ba00109-7b62-4f32-b685-17f437630230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import InterpolationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8603ed7b-af59-4d79-b6a7-dcb599e28e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b216854c-ca48-43e5-8672-070d0ac78392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02414ffa-fc8b-4cd7-a6fa-1f744a9a68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a1d315-3dad-4b75-9595-de862888c419",
   "metadata": {},
   "source": [
    "#### `svetlanna`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c68d7937-25cf-465f-af73-90f208686d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna.units import ureg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "902804f6-c104-4b4b-9b9f-f43ac9b4c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna import SimulationParameters\n",
    "from svetlanna.parameters import ConstrainedParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b7826e8-9de7-4539-b16a-60827a25959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna import Wavefront\n",
    "from svetlanna.transforms import ToWavefront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5a64cdd-5ed6-4fe1-ab77-d95120a45f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna.elements import FreeSpace, Aperture, RectangularAperture, DiffractiveLayer\n",
    "from svetlanna.setup import LinearOpticalSetup\n",
    "from svetlanna.detector import Detector, DetectorProcessorClf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcf3be29-791b-48a3-946b-b300ea0e26e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna.visualization import show_stepwise_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d898096-f89a-4bb4-8bd2-b11d3b044c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna.clerk import Clerk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73440a60-e88a-49d7-81a2-d6a3bed3bf63",
   "metadata": {},
   "source": [
    "#### `src`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cbc8319-2f82-4979-889a-4efcc8466039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset of wavefronts\n",
    "from src.wf_datasets import DatasetOfWavefronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "688215a7-800b-4108-aaa6-807f98b1b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and evaluation loops\n",
    "from src.clf_loops import onn_train_clf, onn_validate_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dfb2cb-94cf-4e83-a079-0a6ec828a66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cea815ac-b473-4d58-a0d5-1253d9740a40",
   "metadata": {},
   "source": [
    "# Optical Neural Network\n",
    "\n",
    "In that example notebook we will try to realize a simple architecture of an optical neural network from the article [[1]](https://www.science.org/doi/10.1126/science.aat8084)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a46e5e-6053-4e74-93eb-fb8e2c8f45a0",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> 1. Simulation parameters (TODO) </span>\n",
    "\n",
    "\n",
    "First of all we need to specify simulation parameters for our task: they includes wavelength $\\lambda$ and a numerical mesh (in our case it corresponds to a neuron size).\n",
    "\n",
    "**<span style=\"color:red\">Sources to use:</span>**\n",
    "[[1]](https://www.science.org/doi/10.1126/science.aat8084) and its [Supplementary Material](https://www.science.org/doi/suppl/10.1126/science.aat8084/suppl_file/aat8084-lin-sm-rev-3.pdf), [[2]](https://ieeexplore.ieee.org/abstract/document/8732486) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68753229-ad8f-4f66-983d-cbe80002cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: specify all variables (now they are None's) using provided sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d815d886-8ffb-4a79-b488-6b207cd05b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_const = 299_792_458 # [m / s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e389f46c-f2ca-4204-a30f-c270e5987163",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_frequency = 400 * ureg.GHz  # [Hz]\n",
    "working_wavelength = c_const / working_frequency  # [m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "257fcf62-f897-4b81-af45-96326d47ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron size (square)\n",
    "neuron_size = 0.53 * working_wavelength  # [m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19dc8771-a0e3-418b-9c0d-a725b21d12c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specified parameters:\n",
      "lambda = 749.481 um\n",
      "neuron size = 397.225 um\n"
     ]
    }
   ],
   "source": [
    "print('Specified parameters:')\n",
    "# uncomment next two lines!\n",
    "print(f'lambda = {working_wavelength * 1e6:.3f} um')\n",
    "print(f'neuron size = {neuron_size * 1e6:.3f} um') # IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6618b4ec-9fe2-45c7-8019-1f3b63c2e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an actual zone where weights will be updated during a training process\n",
    "ALL_SIZE = (200, 200)  # for example (100, 100) neurons\n",
    "USE_APERTURES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb111990-529e-4153-b585-ab0127bfc99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_APERTURES:\n",
    "    # if we will add apertures we must specify the aperture size here!\n",
    "    DETECTOR_SIZE = (None, None)\n",
    "else:\n",
    "    DETECTOR_SIZE = ALL_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1da8d905-67e4-4df9-8686-ce14f1b71b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of neurons in simulation\n",
    "x_layer_nodes = ALL_SIZE[1]\n",
    "y_layer_nodes = ALL_SIZE[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd7d7f13-d150-48be-8e4c-c97ea588ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate physical size of each layer in [m]\n",
    "x_layer_size_m = x_layer_nodes * neuron_size  # [m]\n",
    "y_layer_size_m = y_layer_nodes * neuron_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37057e7b-8ba8-49d4-a9e3-c4b9ece0c7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size (in neurons): 200 x 200 = 40000\n",
      "Layer size (in cm): 7.944500137 x 7.944500137\n"
     ]
    }
   ],
   "source": [
    "print(f'Layer size (in neurons): {x_layer_nodes} x {y_layer_nodes} = {x_layer_nodes * y_layer_nodes}')\n",
    "print(f'Layer size (in cm): {x_layer_size_m * 1e2} x {y_layer_size_m * 1e2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d64da3-9611-4b74-84d0-a706f2c2e3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c3d95cc-633a-481a-bfa6-fe25a1d5b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation parameters for the rest of the notebook!\n",
    "\n",
    "SIM_PARAMS = SimulationParameters(\n",
    "    axes={\n",
    "        \"W\" : torch.linspace(-x_layer_size_m / 2, x_layer_size_m / 2, x_layer_nodes),\n",
    "        \"H\" : torch.linspace(-y_layer_size_m / 2, y_layer_size_m / 2, y_layer_nodes),\n",
    "        \"wavelength\": working_wavelength\n",
    "    }\n",
    ")  # this is a custom object from our library `svetlanna`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d6f07c-1cb7-4b52-87c8-7c5306df2a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddbc9f3f-308d-4c58-b79c-de72e1eeff7b",
   "metadata": {},
   "source": [
    "# 2. Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18398b5-9ee7-470c-b2ef-bcd15b6f4768",
   "metadata": {},
   "source": [
    "## 2.1. [MNIST Dataset](https://www.kaggle.com/datasets/hojjatk/mnist-dataset)\n",
    "\n",
    "Here we load dataset of images but we need to transform them to Wavefronts in order to use them for DNN training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0de278d4-1f7a-4651-8fce-74c41567c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a directory for a dataset\n",
    "MNIST_DATA_FOLDER = './data'  # folder to store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "687971fc-d632-41d7-bf2f-b0ab68e6d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MNIST_DATA_FOLDER):\n",
    "    os.makedirs(MNIST_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab77fa7-dba0-4fbd-bb42-57560fbcac5c",
   "metadata": {},
   "source": [
    "### 2.1.1. Load Train and Test datasets of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1d740b2-dfd1-4bf3-a86c-6fb13a831df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN (images)\n",
    "mnist_train_ds = torchvision.datasets.MNIST(\n",
    "    root=MNIST_DATA_FOLDER,\n",
    "    train=True,  # for train dataset\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14fb6dc4-3849-467c-957d-26617d8c5214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST (images)\n",
    "mnist_test_ds = torchvision.datasets.MNIST(\n",
    "    root=MNIST_DATA_FOLDER,\n",
    "    train=False,  # for test dataset\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208ca22f-13b4-4066-a850-1bd35776637b",
   "metadata": {},
   "source": [
    "## 2.2. Create Train and Test datasets of wavefronts\n",
    "\n",
    "From [[2]](https://ieeexplore.ieee.org/abstract/document/8732486):\n",
    "\n",
    "> Input objects were encoded in amplitude channel (MNIST) of the input plane and were illuminated with a uniform plane wave at a wavelength of $\\lambda$ to match the conditions introduced in [[1]](https://www.science.org/doi/10.1126/science.aat8084) for all-optical classification.\n",
    "\n",
    "So, we need to do an amplitude modulation of each image from the dataset!\n",
    "\n",
    "**<span style=\"color:red\">Comment:</span>**\n",
    "We will see later what does \"amplitude modulation\" mean!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c37007c-0731-4b58-9059-e2f2bb792b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select modulation type\n",
    "MODULATION_TYPE = 'amp'  # using ONLY amplitude to encode each picture in a Wavefront!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6297fd51-0bec-4b90-bf86-0346bc460f2e",
   "metadata": {},
   "source": [
    "### 2.2.1. Transformations of images to Wavefronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88113581-f819-4554-8d6a-db075f713a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_y = int(DETECTOR_SIZE[0] / 2)\n",
    "resize_x = int(DETECTOR_SIZE[1] / 2)  # shape for transforms.Resize\n",
    "\n",
    "# paddings along OY\n",
    "pad_top = int((y_layer_nodes - resize_y) / 2)\n",
    "pad_bottom = y_layer_nodes - pad_top - resize_y\n",
    "# paddings along OX\n",
    "pad_left = int((x_layer_nodes - resize_x) / 2)\n",
    "pad_right = x_layer_nodes - pad_left - resize_x  # params for transforms.Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47e20e55-53f7-4f92-95eb-3ef75d5dddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose all transforms!\n",
    "image_transform_for_ds = transforms.Compose(\n",
    "  [\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Resize(\n",
    "          size=(resize_y, resize_x),\n",
    "          interpolation=InterpolationMode.NEAREST,\n",
    "      ),\n",
    "      transforms.Pad(\n",
    "          padding=(\n",
    "              pad_left,  # left padding\n",
    "              pad_top,  # top padding\n",
    "              pad_right,  # right padding\n",
    "              pad_bottom  # bottom padding\n",
    "          ),\n",
    "          fill=0,\n",
    "      ),  # padding to match sizes!\n",
    "      ToWavefront(modulation_type=MODULATION_TYPE)  # <- select modulation type!!!\n",
    "  ]  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb08e9c-26e0-4241-b2b0-88ea4529e96b",
   "metadata": {},
   "source": [
    "### 2.2.2. Create Dataset objects for train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7309365a-2986-45e8-a259-97f378fcccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN dataset of WAVEFRONTS\n",
    "mnist_wf_train_ds = DatasetOfWavefronts(\n",
    "    init_ds=mnist_train_ds,  # dataset of images\n",
    "    transformations=image_transform_for_ds,  # image transformation\n",
    "    sim_params=SIM_PARAMS,  # simulation parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "873dfbe6-81a1-47ab-9dfd-2f1513044fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST dataset of WAVEFRONTS\n",
    "mnist_wf_test_ds = DatasetOfWavefronts(\n",
    "    init_ds=mnist_test_ds,  # dataset of images\n",
    "    transformations=image_transform_for_ds,  # image transformation\n",
    "    sim_params=SIM_PARAMS,  # simulation parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "038b5a54-175a-433b-98b6-8e37565d19b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 60000\n",
      "Test data : 10000\n"
     ]
    }
   ],
   "source": [
    "print(f'Train data: {len(mnist_train_ds)}')\n",
    "print(f'Test data : {len(mnist_test_ds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76445f5-d5c6-4960-b7ea-d62a42614d1c",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> 2.2.3. Visualisation of dataset items (TODO) </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a11e824c-1200-4219-90b5-9b155206b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: What are the items of `mnist_train_ds`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f750a36-38d7-40ca-9516-faabe49479ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAACzBVBJJwAO9dnp/wm8damu6Dw5dRjGf9IKw/+hkVPffCnWNJa7XVNV0Kxa1hErrNe/M2cnYqgElsAHpjkc1wlAODkV694W8c654t8M6n4TuvEctrrFw0cun3c0/lq+3AMJcDK5AyOeTkd+fPvGFn4gsvEtzF4m89tUG1ZJJjuMgUBVYN/EMKOe9YVXtK0bUtdvVs9LsZ7y4YgbIULYycZPoPc8V6lpfwh0/w7p66z8RdXj0y2z8llC4aWQ+mRn8lz9RXPfE3x1pvi46TYaPZTQadpMJghluWDSyrhQM9SMBe5Oc5NcBV7Tda1XRZJJNK1O8sXkG12tZ2iLD0JUjNQ3l9eahN517dT3MvTfNIXb16n6mq9Ff/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAklEQVR4AWIY1IBZSEiormO91LL/3+tBDmUBESAsx2ZlIxAMYj2ZFPj54kEQixFEMDAwGO7lh7L+JX1lePb+JpQHBkK3/4LAsW3fP4L5qETAnOy/f89yM2jPQhWHAD7GWX+jIEwYyQRjMHz6/5EhBcGFi0MB976/blAmFkr548MFOTD3Y8gHfvj7t1wSQxgKdHf9/TtNGsrBoARi//zdjSEKBz///nSAcuBhC+HrhZiyMFw7BOGgkoCpT3n69+/fX9tQRcE8iaK7oOA96QfmoRDiTldBUscCMQNJaDU4Vg4HcKLoAHHM1zwC6frSyg3iITDYtYGBDAzXN//t+YAQpyULAEUXXoDz1Y8qAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_ex = 0\n",
    "mnist_train_ds[ind_ex][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65cc788f-8eb2-48b9-9360-182595cb4c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wavefront([[0.+0.j, 0.+0.j, 0.+0.j,  ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "            [0.+0.j, 0.+0.j, 0.+0.j,  ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "            [0.+0.j, 0.+0.j, 0.+0.j,  ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "            ...,\n",
       "            [0.+0.j, 0.+0.j, 0.+0.j,  ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "            [0.+0.j, 0.+0.j, 0.+0.j,  ..., 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "            [0.+0.j, 0.+0.j, 0.+0.j,  ..., 0.+0.j, 0.+0.j, 0.+0.j]]),\n",
       " 5)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_wf_train_ds[ind_ex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "849494fd-0a2e-436b-a0ea-61838cdcc874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x960 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot several EXAMPLES from TRAIN dataset\n",
    "n_examples= 4  # number of examples to plot\n",
    "# choosing indecies of images (from train) to plot\n",
    "random.seed(78)\n",
    "train_examples_ids = random.sample(range(len(mnist_train_ds)), n_examples)\n",
    "\n",
    "all_examples_wavefronts = []\n",
    "\n",
    "n_lines = 3\n",
    "fig, axs = plt.subplots(n_lines, n_examples, figsize=(n_examples * 3, n_lines * 3.2))\n",
    "for ind_ex, ind_train in enumerate(train_examples_ids):\n",
    "    image, label = mnist_train_ds[ind_train]\n",
    "    \n",
    "    axs[0][ind_ex].set_title(f'id={ind_train} [{label}]')\n",
    "    axs[0][ind_ex].imshow(image, cmap='gray')\n",
    "\n",
    "    wavefront, wf_label = mnist_wf_train_ds[ind_train]\n",
    "    assert isinstance(wavefront, Wavefront)\n",
    "\n",
    "    all_examples_wavefronts.append(wavefront)\n",
    "\n",
    "    axs[1][ind_ex].set_title(f'$|WF|^2$')\n",
    "    # here we can plot intensity for a wavefront\n",
    "    axs[1][ind_ex].imshow(\n",
    "        wavefront.intensity, cmap='gray',\n",
    "        vmin=0, vmax=1\n",
    "    )\n",
    "    \n",
    "    axs[2][ind_ex].set_title(f'phase of $WF$')\n",
    "    axs[2][ind_ex].imshow(\n",
    "        wavefront.phase, cmap='gray',\n",
    "        vmin=0, vmax= 2 * torch.pi\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b39769-edd7-4085-bb46-cc79dd86029d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73ae7308-f611-4948-a9fd-afa66856dc09",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">3. Optical network (TODO)</span>\n",
    "\n",
    "Using sources realize an architecture with several equidistant diffractive layers!\n",
    "\n",
    "**<span style=\"color:red\">Sources to use:</span>**\n",
    "[[1]](https://www.science.org/doi/10.1126/science.aat8084) and its [Supplementary Material](https://www.science.org/doi/suppl/10.1126/science.aat8084/suppl_file/aat8084-lin-sm-rev-3.pdf), [[2]](https://ieeexplore.ieee.org/abstract/document/8732486) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc004e50-5f52-4cd4-9d51-eeaf999209fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: specify all values\n",
    "# Free space can be optimized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c72dbe6a-b8f5-42cd-9852-74f27fbe23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_DIFF_LAYERS = 3  # number of diffractive layers\n",
    "FREE_SPACE_DISTANCE = 40 * working_wavelength  # [m] - distance between difractive layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de30d8bb-2854-4726-9757-e02fd1ed123e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between layers is 2.998 cm\n"
     ]
    }
   ],
   "source": [
    "print(f'Distance between layers is {FREE_SPACE_DISTANCE * 1e2:.3f} cm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "628a0c01-5dc2-46cb-9ee3-b6d1c0acaa26",
   "metadata": {},
   "source": [
    "## 3.1. Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c017b60c-cb2c-4707-800e-5dfd2770389c",
   "metadata": {},
   "source": [
    "### 3.1.1. Elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "572433d3-ddab-40ec-9fbf-974e0150f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PHASE = 2 * np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24e45194-9345-4287-af3e-27f8ebf6f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREESPACE_METHOD = 'AS'  # we use an angular spectrum method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "01fd8c37-cf07-4272-b2d5-b6b830ccc927",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_PHASES = torch.ones(NUM_OF_DIFF_LAYERS) * np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c8eff4-fd1a-41f2-b5df-056ff54edc2a",
   "metadata": {},
   "source": [
    "#### Functions that return single elements for further architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22411824-c546-4721-99cb-1564445a4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKE A LOOK! CODE HERE IS READY\n",
    "def get_const_phase_layer(\n",
    "    sim_params: SimulationParameters,\n",
    "    value: float, \n",
    "    max_phase=2 * torch.pi\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns DiffractiveLayer with a constant phase mask.\n",
    "    \"\"\"\n",
    "    x_nodes, y_nodes = sim_params.axes_size(axs=('W', 'H'))\n",
    "\n",
    "    const_mask = torch.ones(size=(y_nodes, x_nodes)) * value\n",
    "    \n",
    "    return DiffractiveLayer(\n",
    "        simulation_parameters=sim_params,\n",
    "        mask=ConstrainedParameter(\n",
    "            const_mask,\n",
    "            min_value=0,\n",
    "            max_value=max_phase\n",
    "        ),  # HERE WE ARE USING CONSTRAINED PARAMETER! Phases are learnable!\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b103a40-895b-4915-bdb8-01cab2838c1d",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">3.1.2. List of Elements (TODO)</span>\n",
    "\n",
    "Function to construct a list of elements to reproduce an architecture from [the extended article](https://ieeexplore.ieee.org/abstract/document/8732486):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df37b226-fae8-4c79-a045-ba36c1c200a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add elements (using functions from 3.1.1.) in necessary places!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4e3cf49-5e7f-4fe1-81c9-dd90021c9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elements_list(\n",
    "    num_layers,\n",
    "    simulation_parameters,\n",
    "    freespace_method,\n",
    "    phase_values,\n",
    "    apertures=False,\n",
    "    aperture_size=(100, 100)\n",
    "):\n",
    "    \"\"\"\n",
    "    Composes a list of elements for the setup.\n",
    "    ...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_layers : int\n",
    "        Number of layers in the system.\n",
    "    simulation_parameters : SimulationParameters()\n",
    "        A simulation parameters for a task.\n",
    "    freespace_method : str\n",
    "        Propagation method for free spaces in a setup.\n",
    "    phase_values : torch.Tensor()\n",
    "        Torch tensor of phase values to generate constant masks for diffractive layers.\n",
    "        \n",
    "    apertures : bool\n",
    "        If True, than before each DiffractiveLayer (and detector) we add a square aperture.\n",
    "        Comment: there are strickt square apertures!\n",
    "    aperture_size : tuple\n",
    "        A size of apertures.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    elements_list : list(Element)\n",
    "        List of Elements for an optical setup.\n",
    "    \"\"\"\n",
    "    elements_list = []  # list of elements\n",
    "\n",
    "    # -------------------------------------------------- TODO AFTER THE LINE!\n",
    "    # -----------------------------------------------------------------------\n",
    "    \n",
    "    elements_list.append( # This part is arguable\n",
    "        FreeSpace(\n",
    "            simulation_parameters=simulation_parameters,\n",
    "            distance=FREE_SPACE_DISTANCE, # Here happens unnecessary blurring. Or not?\n",
    "            method=freespace_method\n",
    "        )\n",
    "    )  # first FreeSpace layer before first DiffractiveLayer\n",
    "\n",
    "    # several layers [Aperture + DiffractiveLayer + FreeSpace]\n",
    "    for ind_layer in range(num_layers):\n",
    "\n",
    "        # add square Aperture if needed\n",
    "        if apertures:\n",
    "            elements_list.append(\n",
    "                RectangularAperture(simulation_parameters=simulation_parameters,\n",
    "                                    size=aperture_size)\n",
    "            )\n",
    "            \n",
    "        # add DiffractiveLayer (learnable phase mask) and FreeSpace\n",
    "        elements_list.append(\n",
    "            get_const_phase_layer(\n",
    "                sim_params=simulation_parameters,\n",
    "                value=phase_values[ind_layer],\n",
    "                max_phase=MAX_PHASE\n",
    "            )\n",
    "        )\n",
    "        elements_list.append(\n",
    "            FreeSpace(\n",
    "                simulation_parameters=simulation_parameters,\n",
    "                distance=FREE_SPACE_DISTANCE,\n",
    "                method=freespace_method\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # ----------------------------------------------------------- END OF TODO\n",
    "    # -----------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "    # -----------------------------------------------------------------------\n",
    "    # add add square Aperture before Detector\n",
    "    if apertures:\n",
    "        elements_list.append(\n",
    "            # your code...  # <-------------------------- HERE IS TODO TOO!!!\n",
    "        )\n",
    "    \n",
    "    # adding a Detector in the end of the system\n",
    "    # Detector returns torch.tensor of intencities (not a Wavefront - read documentation)\n",
    "    elements_list.append(\n",
    "        Detector(\n",
    "            simulation_parameters=simulation_parameters,\n",
    "            func='intensity'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return elements_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b12dba0-f5fb-461f-b724-a9ea57895765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "092f0c4c-6b3a-4d43-815e-eefc747922b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FreeSpace(),\n",
       " DiffractiveLayer(\n",
       "   (mask_svtlnn_inner_parameter): InnerParameterStorageModule()\n",
       " ),\n",
       " FreeSpace(),\n",
       " DiffractiveLayer(\n",
       "   (mask_svtlnn_inner_parameter): InnerParameterStorageModule()\n",
       " ),\n",
       " FreeSpace(),\n",
       " DiffractiveLayer(\n",
       "   (mask_svtlnn_inner_parameter): InnerParameterStorageModule()\n",
       " ),\n",
       " FreeSpace(),\n",
       " Detector()]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "architecture_elements_list = get_elements_list(\n",
    "    num_layers=NUM_OF_DIFF_LAYERS,\n",
    "    simulation_parameters=SIM_PARAMS,\n",
    "    freespace_method=FREESPACE_METHOD,\n",
    "    phase_values=INIT_PHASES,\n",
    "    apertures=USE_APERTURES,\n",
    "    aperture_size=DETECTOR_SIZE\n",
    ")\n",
    "architecture_elements_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f2006774-6cd7-4c26-ac94-ea6ca05214b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in the system (including Detector): 8\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of elements in the system (including Detector): {len(architecture_elements_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a34cf91-1e75-4b23-a7d4-84ca094f0529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61958d45-f06e-4292-be5e-e0025dd1b2db",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">3.1.3. Compose `LinearOpticalSetup` (TODO)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "727a9d29-8b31-47e9-b0b0-fdae9d44c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_setup(simulation_parameters, apertures=False):\n",
    "    \"\"\"\n",
    "    Returns an optical setup. Recreates all elements.\n",
    "    \"\"\"\n",
    "    elements_list = get_elements_list(\n",
    "        num_layers=NUM_OF_DIFF_LAYERS,\n",
    "        simulation_parameters=SIM_PARAMS,\n",
    "        freespace_method=FREESPACE_METHOD,\n",
    "        phase_values=INIT_PHASES,\n",
    "        apertures=apertures,\n",
    "        aperture_size=DETECTOR_SIZE\n",
    "    )  # recreate a list of elements\n",
    "\n",
    "    return LinearOpticalSetup(elements=elements_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "762206a1-1bc1-4725-b7dc-53dcb252d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creaye an optical setup\n",
    "optical_setup = get_setup(SIM_PARAMS, apertures=USE_APERTURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "223bd522-f656-45a7-8f0e-ef74ed6aa9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check the architecture!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90ec1286-321e-4444-9f3c-e9d53c5e381a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): FreeSpace()\n",
       "  (1): DiffractiveLayer(\n",
       "    (mask_svtlnn_inner_parameter): InnerParameterStorageModule()\n",
       "  )\n",
       "  (2): FreeSpace()\n",
       "  (3): DiffractiveLayer(\n",
       "    (mask_svtlnn_inner_parameter): InnerParameterStorageModule()\n",
       "  )\n",
       "  (4): FreeSpace()\n",
       "  (5): DiffractiveLayer(\n",
       "    (mask_svtlnn_inner_parameter): InnerParameterStorageModule()\n",
       "  )\n",
       "  (6): FreeSpace()\n",
       "  (7): Detector()\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optical_setup.net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4fc9e8-ce6b-4f8c-b120-6b9ff70630b2",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Comment:</span>** Setup ends with `Detector` that returns an output tensor of intensities for each input `Wavefront`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74616a5a-c1e1-4ab1-b0fd-85f83338a5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0176fa87-f51c-4ef1-bf22-64855a370695",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">3.1.4. Example of a random wavefrnt propagation (TODO)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "10434cb3-2ca2-43ec-9463-c522ecc618a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check how a random wavefront propagates through an untrained system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9480488a-4bb6-4d81-8f68-fa09c4b73c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ind = np.random.randint(0, len(mnist_wf_train_ds))\n",
    "\n",
    "example_wf, example_label = mnist_wf_train_ds[random_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fee1d93e-a61e-4744-be92-f715dee19db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label of selected wavefront: 8\n"
     ]
    }
   ],
   "source": [
    "print(f'Label of selected wavefront: {example_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8538e8b8-911d-475a-bc33-7ed4a161c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: take a look on the visualization below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "defeaf77-da7c-44a4-a284-16f581b699ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old version...\n",
    "# setup_scheme, wavefronts = optical_setup.stepwise_forward(example_wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a7810b55-235b-49ea-9f48-337c87efeca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soflu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\svetlanna\\elements\\diffractive_layer.py:99: RuntimeWarning: invalid value encountered in divide\n",
      "  ImageRepr((255 * (mask - mask_min) / (mask_max - mask_min)).astype('uint8')),\n",
      "C:\\Users\\soflu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\svetlanna\\elements\\diffractive_layer.py:99: RuntimeWarning: invalid value encountered in cast\n",
      "  ImageRepr((255 * (mask - mask_min) / (mask_max - mask_min)).astype('uint8')),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdff894ee7fe4837b3760cc9e4dc5dbe",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "StepwiseForwardWidget(elements=[{'index': 0, 'name': 'LinearOpticalSetup', 'output_image': 'iVBORw0KGgoAAAANSU"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_stepwise_forward(\n",
    "    optical_setup,\n",
    "    input= example_wf,  # TODO: add a wavefront to propagate!\n",
    "    simulation_parameters=SIM_PARAMS,\n",
    "    types_to_plot=(\"I\", \"phase\")  # TODO: check different types! \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435cdfc0-3293-42a6-841f-ac59cd366e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "450c6c03-bd60-4a40-a557-ce3fb0ccd0c6",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">3.2. Detector processor (!TODO!)</span>\n",
    "\n",
    "Here we need to specify size of each detector segment responcible for each digit classification (see sources).\n",
    "\n",
    "Also we need to write a function that returns a detector mask with a desired placement and ordering of segments in a Detector plane!\n",
    "\n",
    "**<span style=\"color:red\">Sources to use:</span>**\n",
    "[[1]](https://www.science.org/doi/10.1126/science.aat8084) and its [Supplementary Material](https://www.science.org/doi/suppl/10.1126/science.aat8084/suppl_file/aat8084-lin-sm-rev-3.pdf), [[2]](https://ieeexplore.ieee.org/abstract/document/8732486) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "91d1e9b5-8703-4201-8743-b54eac91da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_CLASSES = 10  # TODO: how many classes do we have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1dabde-317c-45c3-a9ee-4bffd403b5cb",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">3.2.1. Detector mask (TODO)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8c1e018-fb72-480e-b7a4-5eaf29145ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector_segment_size = 6.4 * working_wavelength  # in neurons (int)\n",
    "detector_segment_size_m = detector_segment_size // neuron_size  # in [m]\n",
    "detector_segment_size_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8aa135-9ddb-41c2-89d3-bf25d37aa04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detector_mask(\n",
    "    segment_size_in_neurons : int,\n",
    "    segment_dist : int,\n",
    "    order_of_digits=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "):\n",
    "    if not len(order_of_digits) == NUMBER_OF_CLASSES:\n",
    "        print('Wrong ordering list!')\n",
    "\n",
    "    t = torch.ones(ALL_SIZE) * -1\n",
    "    upper = [(-1, 1), (0, 1), (1, 1)]\n",
    "    lower = [(-1, -1), (0, -1), (1, -1)]\n",
    "    middle = [(-1.5, 0), (-0.5, 0), (0.5, 0), (1.5, 0)]\n",
    "    \n",
    "    for i, (x, y) in enumerate(lower + middle + upper):\n",
    "        if not i in order_of_digits:\n",
    "            print('Wrong ordering list!')\n",
    "        x_start = int(segment_size_in_neurons + x * segment_dist + ALL_SIZE[1] // 2 - segment_size_in_neurons // 2 - segment_dist // 2)\n",
    "        y_start = int(segment_size_in_neurons + y * segment_dist + ALL_SIZE[0] // 2 - segment_size_in_neurons // 2 - segment_dist // 2)\n",
    "        t[y_start: y_start + int(segment_size_in_neurons), x_start: x_start + int(segment_size_in_neurons)] = order_of_digits[i]\n",
    "        print(f'Adding segment for class {order_of_digits[i]} which is {i}th at ({x_start}, {y_start})')\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31171243-b32c-4261-b850-4c0a6cd5deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(get_detector_mask(detector_segment_size_m, detector_segment_size_m * 2), cmap='gray', vmin=-1, vmax=9)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ff6e7-d778-4aeb-a6b3-a1d828977f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZONES_ORDER = [0, 1, 2, 9, 4, 5, 6, 7, 8, 3]  # TODO% specify the order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eeb7d86b-ab1d-4575-a757-a8ee00f350dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding segment for class 0 which is 0th at (70, 70)\n",
      "Adding segment for class 1 which is 1th at (94, 70)\n",
      "Adding segment for class 2 which is 2th at (118, 70)\n",
      "Adding segment for class 9 which is 3th at (58, 94)\n",
      "Adding segment for class 4 which is 4th at (82, 94)\n",
      "Adding segment for class 5 which is 5th at (106, 94)\n",
      "Adding segment for class 6 which is 6th at (130, 94)\n",
      "Adding segment for class 7 which is 7th at (70, 118)\n",
      "Adding segment for class 8 which is 8th at (94, 118)\n",
      "Adding segment for class 3 which is 9th at (118, 118)\n"
     ]
    }
   ],
   "source": [
    "DETECTOR_MASK = get_detector_mask(segment_size_in_neurons=detector_segment_size_m,\n",
    "    segment_dist=detector_segment_size_m * 2,  # distance between segments in\n",
    "    # place for your code\n",
    "    order_of_digits=ZONES_ORDER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5076b296-30ed-447f-bf87-c07355c447d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO*: add your function as a file in src/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b79963c-18c5-4620-82cb-2485a986a1fd",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">3.2.2. Detector processor (TODO)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cb2adcfd-788b-4939-8471-b87b95c31b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DetectorProcessorOzcanClf object\n",
    "DETECTOR_PROCESSOR = DetectorProcessorClf(\n",
    "    simulation_parameters=SIM_PARAMS,\n",
    "    num_classes=NUMBER_OF_CLASSES,\n",
    "    segmented_detector=DETECTOR_MASK,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7b78df3d-748c-4de0-8140-57aac09888dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "de33d6a2-253b-4b4a-82a7-44254e479cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax0 = plt.subplots(1, 1, figsize=(3, 3))\n",
    "\n",
    "ax0.set_title(f'Detector segments')\n",
    "ax0.imshow(DETECTOR_PROCESSOR.segmented_detector, cmap='grey')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec8806d-73da-4907-ae26-c3622d17553c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2651f63-1063-4b9b-bfb1-b3d0d543babc",
   "metadata": {},
   "source": [
    "#### To visualize detector zones (for further use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7b6bc396-cfbb-40a0-9bfe-e12987f9e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZONES_HIGHLIGHT_COLOR = 'w'\n",
    "ZONES_LW = 0.5\n",
    "selected_detector_mask = DETECTOR_PROCESSOR.segmented_detector.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bd154079-4d24-4787-9304-df43fd2b7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zones_patches(detector_mask):\n",
    "    \"\"\"\n",
    "    Returns a list of patches to draw zones in final visualisation\n",
    "    \"\"\"\n",
    "    zones_patches = []\n",
    "\n",
    "    delta = 0.5\n",
    "    \n",
    "    for ind_class in range(number_of_classes):\n",
    "        idx_y, idx_x = (detector_mask == ind_class).nonzero(as_tuple=True)\n",
    "        \n",
    "        zone_rect = patches.Rectangle(\n",
    "            (idx_x[0] - delta, idx_y[0] - delta), \n",
    "            idx_x[-1] - idx_x[0] + 2 * delta, idx_y[-1] - idx_y[0] + 2 * delta, \n",
    "            linewidth=ZONES_LW, \n",
    "            edgecolor=ZONES_HIGHLIGHT_COLOR,\n",
    "            facecolor='none'\n",
    "        )\n",
    "        \n",
    "        zones_patches.append(zone_rect)\n",
    "\n",
    "    return zones_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c36a79-6ebf-49c6-97f8-dbbe89885b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9bf3718-ed29-4fcc-9474-c5d7909b9970",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">4. Training of the network (TODO)</span>\n",
    "\n",
    "Variables at the moment\n",
    "- `optical_setup` : `LinearOpticalSetup`  a linear optical network composed of Elements\n",
    "- `detector_processor` : `DetectorProcessorClf`  this layer process an image from the detector and calculates probabilities of belonging to classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7782668c-2abd-4321-949a-8de50dd8e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'\n",
    "# 'cuda' will be tested in another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9c37298b-6f84-4586-81d2-80268e84c566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78553183-6043-4f46-8910-e33f0dc3a1a3",
   "metadata": {},
   "source": [
    "## 4.1. Prepare some stuff for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec8cc8c-1876-4790-a012-48f2474e7e74",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">4.1.1. `DataLoaders` (TODO)</span>\n",
    "\n",
    "**<span style=\"color:red\">Sources to use:</span>**\n",
    "[[1]](https://www.science.org/doi/10.1126/science.aat8084) and its [Supplementary Material](https://www.science.org/doi/suppl/10.1126/science.aat8084/suppl_file/aat8084-lin-sm-rev-3.pdf), [[2]](https://ieeexplore.ieee.org/abstract/document/8732486) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4211af00-962e-4f64-837d-8b0f40ff2639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Specify batch sizes for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d3dd9a8b-3e30-44df-8335-099fb140cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bs = 20  # a batch size for training set\n",
    "val_bs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c91326-5104-4c52-8ca8-68961010a7dc",
   "metadata": {},
   "source": [
    "#### Train/Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "33ca736b-a938-416e-9362-40c22136c566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: specify a random seed\n",
    "train_val_split_seed = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1eaacee1-7361-4d4c-83d6-815ccebaebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_wf_train_ds\n",
    "train_wf_ds, val_wf_ds = torch.utils.data.random_split(\n",
    "    dataset=mnist_wf_train_ds,\n",
    "    lengths=[55000, 5000],  # sizes from the article\n",
    "    generator=torch.Generator().manual_seed(train_val_split_seed)  # for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "43c3fbef-5a00-4784-a5c8-85c47231890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wf_loader = torch.utils.data.DataLoader(\n",
    "    train_wf_ds,\n",
    "    batch_size=train_bs,\n",
    "    shuffle=True,\n",
    "    # num_workers=2,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "val_wf_loader = torch.utils.data.DataLoader(\n",
    "    val_wf_ds,\n",
    "    batch_size=val_bs,\n",
    "    shuffle=False,\n",
    "    # num_workers=2,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff84f0d-925b-407c-a506-4d02c35fd4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffb8ff99-0e12-4502-9219-40718ef15852",
   "metadata": {},
   "source": [
    "### 4.1.2. Optimizer and loss function\n",
    "\n",
    "Info from a supplementary material of [[1]](https://www.science.org/doi/suppl/10.1126/science.aat8084/suppl_file/aat8084-lin-sm-rev-3.pdf) for MNIST classification:\n",
    "\n",
    "> We used the stochastic gradient descent algorithm, Adam, to back-propagate the errors and update the\n",
    "layers of the network to minimize the loss function.\n",
    "\n",
    "**<span style=\"color:red\">Additional info</span>** from [[2]](https://ieeexplore.ieee.org/abstract/document/8732486):\n",
    "> a back-propagation method by applying the adaptive moment estimation optimizer (Adam) with a learning rate of $10^{3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b61be8c4-f379-4987-a314-2f7e17eef84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8fbf825c-e9ca-4f94-b1d6-da4921748cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adam_optimizer(net):\n",
    "    return torch.optim.Adam(\n",
    "        params=net.parameters(),  # NETWORK PARAMETERS!\n",
    "        lr=LR\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "390a425d-cff3-44ba-81f6-2fe467c52a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func_clf = nn.CrossEntropyLoss()\n",
    "loss_func_name = 'CE loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09af0a6d-09b9-4235-b10d-86cd5af1b178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7381166-44cd-4136-a67b-e703fd1d8509",
   "metadata": {},
   "source": [
    "### 4.1.3. Training and evaluation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6712d830-8a01-4f32-b2be-17631fad71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are just importing them from src folder\n",
    "from src.clf_loops import onn_train_clf, onn_validate_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea484d71-20a9-4590-be00-32eb052cedbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5916b72f-dacb-47b0-a41c-853b430f4f89",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">4.2. Training of the optical network (TODO)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d19488d-031b-43ed-909c-562fbeb76c59",
   "metadata": {},
   "source": [
    "### 4.2.1. Before training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224a3df0-4bc1-41e0-aaa0-fc75c04f3f8c",
   "metadata": {},
   "source": [
    "> a diffractive layer ... neurons ... were initialized with $\\pi$ for phase values and $1$ for amplitude values ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c5c93e-de70-415c-a940-4bf1cb03d5e6",
   "metadata": {},
   "source": [
    "#### Metrics for Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0523bf4f-a304-4240-aae7-f12ff846565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wf_loader = torch.utils.data.DataLoader(\n",
    "    mnist_wf_test_ds,\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    "    # num_workers=2,\n",
    "    drop_last=False,\n",
    ")  # data loader for a test MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "28abb09f-0423-47da-8b7f-c5e4a1a3aa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|| 1000/1000 [01:12<00:00, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results before training on TEST set:\n",
      "\tCE loss : 2.292468\n",
      "\tAccuracy : 14.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_losses_0, _, test_accuracy_0 = onn_validate_clf(\n",
    "    optical_setup.net,  # optical network composed in 3.\n",
    "    test_wf_loader,  # dataloader of training set\n",
    "    DETECTOR_PROCESSOR,  # detector processor\n",
    "    loss_func_clf,\n",
    "    device=DEVICE,\n",
    "    show_process=True,\n",
    ")  # evaluate the model\n",
    "\n",
    "print(\n",
    "    'Results before training on TEST set:\\n' + \n",
    "    f'\\t{loss_func_name} : {np.mean(test_losses_0):.6f}\\n' +\n",
    "    f'\\tAccuracy : {(test_accuracy_0 * 100):>0.1f} %'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6142a33b-e47f-4283-bc30-13165b96fedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de9a5938-095b-4e9a-8994-1e82ccdc2382",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> 4.2.2. Some values for training (TODO)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7dcf84ea-7736-4e35-a7fc-ccfd9f01f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: specify values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6af66260-159f-4656-a35e-df434135e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4b359fab-022f-452b-9355-38146bdd307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TORCH_SEED = 4  # for reproducability (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c873837a-4e9a-47b0-9fd2-0c094f72d438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b091229-3c2a-4233-8459-f3ffd528e9bc",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> 4.2.3. Save all parameters in file (TODO)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b84bddc9-a09c-4a81-a27c-a7a5818aee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "today_date = datetime.today().strftime('%d-%m-%Y_%H-%M')  # date for a results folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "adb36cb0-7e9a-4c46-8611-0a1bed807d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/exp_23-06-2025_14-57'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULTS_FOLDER = f'results/exp_{today_date}'\n",
    "RESULTS_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3c7c4b-9939-4f48-9ef8-8bb81c1a5a57",
   "metadata": {},
   "source": [
    "#### Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4af6f2ad-7106-4d6d-b2e4-3cc5eb733920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: maybe add some other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "26960bc3-bf42-4cc2-8185-cf4a3b4c5d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIABLES = {    \n",
    "    'wavelength': working_wavelength,  # working wavelength, in [m]\n",
    "    'neuron_size': neuron_size,  # size of a pixel for DiffractiveLayers, in [m]\n",
    "    'mesh_size': ALL_SIZE,  # full size of a layer = numerical mesh\n",
    "    'use_apertures': USE_APERTURES,  # if we need to add apertures before each DiffractieLayer\n",
    "    'aperture_size': DETECTOR_SIZE,  # size of each aperture = a detector square for classes zones\n",
    "    \n",
    "    # DETECTOR ZONES\n",
    "    'detector_segment_size': detector_segment_size_m,  # size of each square class zone on a detector, in [m]\n",
    "    'segments_order': ZONES_ORDER,\n",
    "\n",
    "    # RANDOM SEEDS\n",
    "    'train_val_seed': train_val_split_seed,\n",
    "    'torch_seed': TORCH_SEED,\n",
    "    \n",
    "    # NETWORK - SECTION 3 of the notebook\n",
    "    'free_space_distance': FREE_SPACE_DISTANCE,  # constant free space distance for a network, in [m]\n",
    "    \n",
    "    # OPTICAL NETWORK LEARNING - SECTION 4 of the notebook\n",
    "    'train_batch_size': train_bs,  # batch sizes for training\n",
    "    'val_batch_size': val_bs,\n",
    "    'adam_lr': LR,  # learning rate for Adam optimizer\n",
    "    'number_of_epochs': NUM_EPOCHS,  # number of epochs to train\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6c8b86ab-1e41-4e65-b1af-85b2c481e75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(RESULTS_FOLDER):\n",
    "    os.makedirs(RESULTS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "879df5ac-6ddf-42b1-a06f-3edec06055db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# save experiment conditions (VARIABLES dictionary)\n",
    "with open(f'{RESULTS_FOLDER}/conditions.json', 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(VARIABLES, json_file, ensure_ascii = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e0c116-df7c-4267-a696-f1db17286ed7",
   "metadata": {},
   "source": [
    "#### Detector mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "82f28b00-c1ba-4d2a-bc7b-ce56c5be77da",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(DETECTOR_MASK, f'{RESULTS_FOLDER}/detector_mask.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f8481-fe79-47af-8777-10b54a5c38a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b263dc4-4c9d-41a6-8f89-bfdb860a4273",
   "metadata": {},
   "source": [
    "### 4.2.4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2ce8ef8d-dd2a-4bb6-8b6d-ca3792dbc6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_each = 1  # print each n'th epoch info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6adb8840-df52-425c-bacf-0cfea6e8c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = None  # sheduler for a lr tuning during training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c58a2fc5-fed3-4730-ae75-bb814ab0daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate a system to restart training!\n",
    "optical_setup_to_train = get_setup(SIM_PARAMS, apertures=USE_APERTURES)\n",
    "# Link optimizer to a recreated net!\n",
    "optimizer_clf = get_adam_optimizer(optical_setup_to_train.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "158d9843-5ca6-42bc-84b2-eb67f25fcc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: RUN TRAINING! Look on losses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d3cd09-a569-40ef-ab30-a1b4a1ce6531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|| 2750/2750 [08:27<00:00,  5.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results\n",
      "\tCE loss : 2.089467\n",
      "\tAccuracy : 58.5 %\n",
      "\t------------   507.06 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|| 625/625 [00:33<00:00, 18.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results\n",
      "\tCE loss : 1.979181\n",
      "\tAccuracy : 75.5 %\n",
      "\t------------   33.12 s\n",
      "Epoch #2: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|| 2750/2750 [08:51<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results\n",
      "\tCE loss : 1.941359\n",
      "\tAccuracy : 78.4 %\n",
      "\t------------   531.24 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|| 625/625 [00:30<00:00, 20.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results\n",
      "\tCE loss : 1.913662\n",
      "\tAccuracy : 81.2 %\n",
      "\t------------   30.93 s\n",
      "Epoch #3: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|| 2750/2750 [08:46<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results\n",
      "\tCE loss : 1.899719\n",
      "\tAccuracy : 81.4 %\n",
      "\t------------   526.84 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|| 625/625 [00:34<00:00, 17.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results\n",
      "\tCE loss : 1.888265\n",
      "\tAccuracy : 82.1 %\n",
      "\t------------   34.95 s\n",
      "Epoch #4: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|| 2750/2750 [08:11<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results\n",
      "\tCE loss : 1.881627\n",
      "\tAccuracy : 82.5 %\n",
      "\t------------   491.52 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|| 625/625 [00:29<00:00, 20.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results\n",
      "\tCE loss : 1.875697\n",
      "\tAccuracy : 82.9 %\n",
      "\t------------   29.95 s\n",
      "Epoch #5: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  16%|                                                                                                          | 427/2750 [01:17<06:19,  6.12it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[359]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# TRAIN\u001b[39;00m\n\u001b[32m     17\u001b[39m start_train_time = time.time()  \u001b[38;5;66;03m# start time of the epoch (train)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m train_losses, _, train_accuracy = \u001b[43monn_train_clf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptical_setup_to_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# optical network composed in 3.\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_wf_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# dataloader of training set\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mDETECTOR_PROCESSOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# detector processor\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_func_clf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer_clf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_process\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[32m     27\u001b[39m mean_train_loss = np.mean(train_losses)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (epoch == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ((epoch + \u001b[32m1\u001b[39m) % print_each == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (epoch == n_epochs - \u001b[32m1\u001b[39m):  \u001b[38;5;66;03m# train info\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\soflu\\Desktop\\DNN\\src\\clf_loops.py:73\u001b[39m, in \u001b[36monn_train_clf\u001b[39m\u001b[34m(optical_net, wavefronts_dataloader, detector_processor_clf, loss_func, optimizer, device, show_process)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# calculate loss for a batch\u001b[39;00m\n\u001b[32m     71\u001b[39m loss = loss_func(batch_probas, batch_labels)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m optimizer.step()\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# accuracy\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\soflu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\soflu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\soflu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_epochs_losses = []\n",
    "val_epochs_losses = []  # to store losses of each epoch\n",
    "\n",
    "train_epochs_acc = []\n",
    "val_epochs_acc = []  # to store accuracies\n",
    "\n",
    "torch.manual_seed(TORCH_SEED)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    if (epoch == 0) or ((epoch + 1) % print_each == 0) or (epoch == n_epochs - 1):\n",
    "        print(f'Epoch #{epoch + 1}: ', end='')\n",
    "        show_progress = True\n",
    "    else:\n",
    "        show_progress = False\n",
    "\n",
    "    # TRAIN\n",
    "    start_train_time = time.time()  # start time of the epoch (train)\n",
    "    train_losses, _, train_accuracy = onn_train_clf(\n",
    "        optical_setup_to_train.net,  # optical network composed in 3.\n",
    "        train_wf_loader,  # dataloader of training set\n",
    "        DETECTOR_PROCESSOR,  # detector processor\n",
    "        loss_func_clf,\n",
    "        optimizer_clf,\n",
    "        device=DEVICE,\n",
    "        show_process=show_progress,\n",
    "    )  # train the model\n",
    "    mean_train_loss = np.mean(train_losses)\n",
    "    \n",
    "    if (epoch == 0) or ((epoch + 1) % print_each == 0) or (epoch == n_epochs - 1):  # train info\n",
    "        print('Training results')\n",
    "        print(f'\\t{loss_func_name} : {mean_train_loss:.6f}')\n",
    "        print(f'\\tAccuracy : {(train_accuracy*100):>0.1f} %')\n",
    "        print(f'\\t------------   {time.time() - start_train_time:.2f} s')\n",
    "\n",
    "    # VALIDATION\n",
    "    start_val_time = time.time()  # start time of the epoch (validation)\n",
    "    val_losses, _, val_accuracy = onn_validate_clf(\n",
    "        optical_setup_to_train.net,  # optical network composed in 3.\n",
    "        val_wf_loader,  # dataloader of validation set\n",
    "        DETECTOR_PROCESSOR,  # detector processor\n",
    "        loss_func_clf,\n",
    "        device=DEVICE,\n",
    "        show_process=show_progress,\n",
    "    )  # evaluate the model\n",
    "    mean_val_loss = np.mean(val_losses)\n",
    "    \n",
    "    if (epoch == 0) or ((epoch + 1) % print_each == 0) or (epoch == n_epochs - 1):  # validation info\n",
    "        print('Validation results')\n",
    "        print(f'\\t{loss_func_name} : {mean_val_loss:.6f}')\n",
    "        print(f'\\tAccuracy : {(val_accuracy*100):>0.1f} %')\n",
    "        print(f'\\t------------   {time.time() - start_val_time:.2f} s')\n",
    "            \n",
    "    if scheduler:\n",
    "        scheduler.step(mean_val_loss) \n",
    "    \n",
    "    # save losses\n",
    "    train_epochs_losses.append(mean_train_loss)\n",
    "    val_epochs_losses.append(mean_val_loss)\n",
    "    # seve accuracies\n",
    "    train_epochs_acc.append(train_accuracy)\n",
    "    val_epochs_acc.append(val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ba775-fce1-4723-885b-3620fe1aa85b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c27f31b5-ccc7-4600-baa0-04c7fe079f50",
   "metadata": {},
   "source": [
    "### 4.2.5. Saving results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2e306a-d3ed-4795-abe7-5e5e7a2c0880",
   "metadata": {},
   "source": [
    "#### Plot and save losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb9f4e-01de-437c-8f42-fea50e0f3b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curve\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "axs[0].plot(range(1, NUM_EPOCHS + 1), train_epochs_losses, label='train')\n",
    "axs[0].plot(range(1, NUM_EPOCHS + 1), val_epochs_losses, linestyle='dashed', label='validation')\n",
    "\n",
    "axs[1].plot(range(1, NUM_EPOCHS + 1), train_epochs_acc, label='train')\n",
    "axs[1].plot(range(1, NUM_EPOCHS + 1), val_epochs_acc, linestyle='dashed', label='validation')\n",
    "\n",
    "axs[0].set_ylabel(loss_func_name)\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2253b04d-a26e-4b8c-aade-819c3771b869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964329df-2cd0-4292-b5b3-e3fbd15decba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# array with all losses\n",
    "all_lasses_header = ','.join([\n",
    "    f'{loss_func_name.split()[0]}_train', f'{loss_func_name.split()[0]}_val',\n",
    "    'accuracy_train', 'accuracy_val'\n",
    "])\n",
    "all_losses_array = np.array(\n",
    "    [train_epochs_losses, val_epochs_losses, train_epochs_acc, val_epochs_acc]\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0894e6ea-cdcb-473f-9892-ee87770c6941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath to save losses\n",
    "losses_filepath = f'{RESULTS_FOLDER}/training_curves.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b11433-0efc-4ae7-9053-dac28cee6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving losses\n",
    "np.savetxt(\n",
    "    losses_filepath, all_losses_array,\n",
    "    delimiter=',', header=all_lasses_header, comments=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a15ac-537f-453d-b404-31fbc5389ddb",
   "metadata": {},
   "source": [
    "#### Save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3535ab45-1f1f-418f-994c-c2c3c8f1a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath to save the model\n",
    "model_filepath = f'{RESULTS_FOLDER}/optical_net.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663cd0ce-07a1-4221-a09c-dadc7a34232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "torch.save(optical_setup_to_train.net.state_dict(), model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc99c34a-f60a-46ee-8d24-b43f28b7c4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c7d2c3-ac64-4b78-85b9-3fd4f692846c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103b80f0-9743-4fe9-a6e9-95a1e84204d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20be9d-c4da-476b-822f-fb431d1d4ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672b668-b6c1-49a5-bb38-610fad3dd7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb1247c6-9e1c-464c-8f9b-6330c56bfb52",
   "metadata": {},
   "source": [
    "# 5. Load model and estimate perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ea42d7-0532-46a8-8f72-3cc2908c6a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_FOLDER = f'results/...'  # select experiment folder!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecb3122-ca66-4b28-be8c-7a3bf6d8fb71",
   "metadata": {},
   "source": [
    "## 5.1. Loading of saved results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d51a4f-7aeb-4da8-8394-d237c3978317",
   "metadata": {},
   "source": [
    "### 5.1.1. Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12eb94-dcaa-4034-b56a-9657a0cd7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{RESULTS_FOLDER}/conditions.json') as json_file:\n",
    "    LOADED_VARIABLES = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30cbf38-77de-4df0-8094-25be5a19a47e",
   "metadata": {},
   "source": [
    "### 5.1.2. Weights of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de870579-4415-4018-a3f4-ed7fa1d04f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init setup to load weights\n",
    "optical_setup_loaded = get_setup(SIM_PARAMS, LOADED_VARIABLES['use_apertures'])\n",
    "# LOAD WEIGHTS for the model\n",
    "optical_setup_loaded.net.load_state_dict(torch.load(f'{LOAD_FOLDER}/optical_net.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3372ffd6-f7a1-4d1d-b4e3-800a77b5bf98",
   "metadata": {},
   "source": [
    "### 5.1.3. Detector processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593decb5-3bc8-481d-bacf-faf6606b9ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTOR_MASK_LOADED = torch.load(f'{LOAD_FOLDER}/detector_mask.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bb9910-2f90-451d-ad08-f89c24194960",
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTOR_PROCESSOR_LOADED = DetectorProcessorClf(\n",
    "    simulation_parameters=SIM_PARAMS,\n",
    "    num_classes=NUMBER_OF_CLASSES,\n",
    "    segmented_detector=DETECTOR_MASK_LOADED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d7330d-a12c-4078-acc7-352cfdfe1df8",
   "metadata": {},
   "source": [
    "### 5.1.4. Trained phase masks visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11683040-3e27-4377-959c-bea12a776875",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = NUM_OF_DIFF_LAYERS  # number of columns for DiffractiveLayer's masks visualization\n",
    "n_rows = 1\n",
    "\n",
    "# plot wavefronts phase\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 3, n_rows * 3.2))\n",
    "ind_diff_layer = 0\n",
    "\n",
    "cmap = 'gist_stern'  # 'gist_stern' 'rainbow'\n",
    "\n",
    "for ind_layer, layer in enumerate(optical_setup_loaded.net):\n",
    "    if isinstance(layer, elements.DiffractiveLayer):  # plot masks for Diffractive layers\n",
    "        if n_rows > 1:\n",
    "            ax_this = axs[ind_diff_layer // n_cols][ind_diff_layer % n_cols]\n",
    "        else:\n",
    "            ax_this = axs[ind_diff_layer % n_cols]\n",
    "\n",
    "        ax_this.set_title(f'{ind_diff_layer + 1}. DiffractiveLayer')\n",
    "\n",
    "        trained_mask = layer.mask.detach()\n",
    "        \n",
    "        ax_this.imshow(         \n",
    "            trained_mask, cmap=cmap,\n",
    "            vmin=0, vmax=MAX_PHASE\n",
    "        )\n",
    "        ind_diff_layer += 1\n",
    "\n",
    "    # select only a part within apertures!\n",
    "    x_frame = (x_layer_nodes - DETECTOR_SIZE[1]) / 2\n",
    "    y_frame = (y_layer_nodes - DETECTOR_SIZE[0]) / 2\n",
    "    ax_this.set_xlim([x_frame, x_layer_nodes - x_frame])\n",
    "    ax_this.set_ylim([y_frame, y_layer_nodes - y_frame])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6a8c7-c74a-414a-923d-4f080708b8b5",
   "metadata": {},
   "source": [
    "## 5.2. Calculate metrics on test set for the loaded model\n",
    "\n",
    "Checking if the loaded model works correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98333cf9-832f-46ac-8bfa-fef032846a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses_1, _, test_accuracy_1 = onn_validate_clf(\n",
    "    optical_setup_loaded.net,  # optical network with loaded weights\n",
    "    test_wf_loader,  # dataloader of training set\n",
    "    detector_processor,  # detector processor\n",
    "    loss_func_clf,\n",
    "    device=DEVICE,\n",
    "    show_process=True,\n",
    ")  # evaluate the model\n",
    "\n",
    "print(\n",
    "    'Results after training on TEST set:\\n' + \n",
    "    f'\\t{loss_func_name} : {np.mean(test_losses_1):.6f}\\n' +\n",
    "    f'\\tAccuracy : {(test_accuracy_1 * 100):>0.1f} %'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ced0a-7948-4685-bd4e-57ef9e58adfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f47740db-90ff-4b2f-a362-7731a460e768",
   "metadata": {},
   "source": [
    "## 5.3. Example of classification (propagation through the setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba54cc2-d8df-4df5-8aed-08c4f0bd89be",
   "metadata": {},
   "source": [
    "### 5.3.1. Select a sample to propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc4e7e-cfb7-4ed3-9caf-87bc39b7ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot an image\n",
    "# '1' - 3214, good\n",
    "# '4' - 6152, good\n",
    "# '6' - 123, good\n",
    "# '8' - 128, good\n",
    "# '0' - 3, good\n",
    "ind_test = 123\n",
    "cmap = 'hot'\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(2 * 3, 3))\n",
    "\n",
    "test_wavefront, test_target = mnist_wf_test_ds[ind_test]\n",
    "\n",
    "axs[0].set_title(f'intensity (id={ind_test})')\n",
    "axs[0].imshow(test_wavefront.intensity, cmap=cmap)\n",
    "\n",
    "axs[1].set_title(f'phase')\n",
    "axs[1].imshow(\n",
    "    test_wavefront.phase, cmap=cmap,\n",
    "    vmin=0, vmax=2 * torch.pi\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f725f858-61f1-4157-978e-a71403c67701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# propagation of the example through the trained network\n",
    "setup_scheme, test_wavefronts = optical_setup_loaded.stepwise_forward(test_wavefront)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70f1ec-3389-4a0c-9645-9e345efec8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eedbd9ee-c50a-4b73-b38c-a3aa6b9a62d6",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> 5.3.2. Stepwise propagation (TODO)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69f0a7f-7c81-41ba-b046-8c2242785c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: see what happens with a wavefront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be9d3b1-8c2a-4bc7-83ef-de796b645e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: aad your code to see^ how the wavefront propagates through a trained optical network!\n",
    "\n",
    "# your code... (Hint: we already did it earlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fe04f6-1b44-4959-b207-d03556706390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3dc20fc-647b-4434-9603-45ff80c09059",
   "metadata": {},
   "source": [
    "### 5.3.3. Detector picture (enlarged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c616ff93-51d4-412d-8475-4cb33954aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure with subplots\n",
    "fig, ax_this = plt.subplots(1, 1, figsize=(3, 3.2))\n",
    "\n",
    "# Detector output (not a wavefront!)\n",
    "ax_this.set_title('Detector Intensity')\n",
    "ax_this.imshow(\n",
    "    test_wavefronts[-1].detach().numpy(), cmap='hot',\n",
    "    # vmin=0, vmax=1  # uncomment to make the same limits\n",
    ")\n",
    "\n",
    "for zone in get_zones_patches(detector_squares_mask):\n",
    "    # add zone's patches to the axis\n",
    "    ax_this.add_patch(zone)\n",
    "\n",
    "# select only a part within apertures! uncomment if needed\n",
    "# x_frame = (x_layer_nodes - DETECTOR_SIZE[1]) / 2\n",
    "# y_frame = (y_layer_nodes - DETECTOR_SIZE[0]) / 2\n",
    "\n",
    "# plt.axis([x_frame, x_layer_nodes - x_frame, y_layer_nodes - y_frame, y_frame])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392dd721-c8de-4e54-bf55-931c498c4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities of an example classification\n",
    "test_probas = detector_processor.forward(test_wavefronts[-1])\n",
    "# Comment: forward() method is from DetectorProcessorClf\n",
    "#          p_i = I(detector_i) / sum_j(I(detector_j))\n",
    "# Comment: It's another output than for batch_forward, that was used during training!\n",
    "\n",
    "assert np.isclose(test_probas.sum().item(), 1)\n",
    "\n",
    "for label, prob in enumerate(test_probas[0]):\n",
    "    print(f'{label} : {prob * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a24a10-101d-4862-b731-94a6470a0fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a8efd33-3e87-4257-93d4-aec5237c315e",
   "metadata": {},
   "source": [
    "## 5.3. Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3334d3-dbd2-44ba-a63e-5f7986ffdb09",
   "metadata": {},
   "source": [
    "### 5.3.1. Predict all Test dataset and save all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0ea29-4c28-443c-8b7f-50efac14ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_test_lst = []\n",
    "preds_test_lst = []  # lists of targets and model predictioons\n",
    "\n",
    "# loop over the test dataset\n",
    "for ind, (wavefront_this, target_this) in enumerate(tqdm(mnist_wf_test_ds)):\n",
    "    optical_setup_loaded.net.eval()\n",
    "    \n",
    "    batch_wavefronts = torch.unsqueeze(wavefront_this, 0)\n",
    "    batch_labels = torch.unsqueeze(torch.tensor(target_this), 0)  # to use forwards for batches\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        detector_output = optical_setup_loaded.net(batch_wavefronts)\n",
    "        # process a detector image\n",
    "        batch_probas = DETECTOR_PROCESSOR_LOADED.batch_forward(detector_output)\n",
    "\n",
    "        for ind_in_batch in range(batch_labels.size()[0]):\n",
    "            label_this = batch_labels[ind_in_batch].item()  # true label\n",
    "            \n",
    "            targets_test_lst.append(label_this)\n",
    "            preds_test_lst.append(batch_probas[ind_in_batch].argmax().item())\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75901f71-c34a-4d4f-a5a6-0b475d058fb6",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> 5.3.2. Confusion matrix (TODO) </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cca796-1fe3-4905-810b-d3f4cfc19231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill the confusion matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a26dd6-81dc-4e7e-b53d-13f2dd553ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinary confusion matrix\n",
    "confusion_matrix = torch.zeros(\n",
    "    size=(mat_y_size, mat_x_size),  # TODO: What is the size of the matrix?\n",
    "    dtype=torch.int32\n",
    ")\n",
    "\n",
    "for ind in range(len(mnist_wf_test_ds)):\n",
    "    confusion_matrix[targets_test_lst[ind], preds_test_lst[ind]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e407677-0e7e-43fe-a2a2-41188d0f66e0",
   "metadata": {},
   "source": [
    "#### Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a93b72-1815-478f-9914-7f78f400a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax0 = plt.subplots(1, 1, figsize=(6, 5))\n",
    "\n",
    "# CONFUSION MATRIX\n",
    "ax0.set_title('Confusion matrix')\n",
    "ax0.matshow(confusion_matrix, cmap='Blues')\n",
    "\n",
    "for i in range(NUMBER_OF_CLASSES):\n",
    "    for j in range(NUMBER_OF_CLASSES):\n",
    "        val = confusion_matrix[j, i].item()\n",
    "        ax0.text(\n",
    "            i, j, str(val),\n",
    "            va='center', ha='center', \n",
    "            c='k', fontsize=9\n",
    "        )\n",
    "\n",
    "ax0.set_ylabel('Target')\n",
    "ax0.set_xlabel('Predicted')\n",
    "\n",
    "ax0.set_xticks(range(number_of_classes))\n",
    "ax0.set_yticks(range(number_of_classes))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# save figure\n",
    "# fig.savefig(f'{LOAD_FOLDER}/confusion_matrix.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d5408-e930-4479-a5a1-d7c576bbf554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make some conclusions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5592d4b4-0ea4-456b-9d65-5f56e915ee6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
