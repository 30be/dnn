{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35c58e4e-9226-4d24-ae10-b84c5cc05ce5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15a31da-c6c3-427d-a070-afdc48a01305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f0f6378-5bc3-477d-bfd3-a08a9123b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f309cc84-f338-409f-b1a3-6ac36b945622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39328b9-9fa8-4937-9a53-905ea59276c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59041be7-8d30-4981-a3da-e5d090a32339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72e92418-e8e7-4baa-882f-92b87f2c68ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ba00109-7b62-4f32-b685-17f437630230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import InterpolationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8603ed7b-af59-4d79-b6a7-dcb599e28e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b216854c-ca48-43e5-8672-070d0ac78392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02414ffa-fc8b-4cd7-a6fa-1f744a9a68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a1d315-3dad-4b75-9595-de862888c419",
   "metadata": {},
   "source": [
    "#### `svetlanna`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c68d7937-25cf-465f-af73-90f208686d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna.units import ureg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "902804f6-c104-4b4b-9b9f-f43ac9b4c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna import SimulationParameters\n",
    "from svetlanna.parameters import ConstrainedParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b7826e8-9de7-4539-b16a-60827a25959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna import Wavefront\n",
    "from svetlanna.transforms import ToWavefront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5a64cdd-5ed6-4fe1-ab77-d95120a45f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna.elements import FreeSpace, Aperture, RectangularAperture, DiffractiveLayer\n",
    "from svetlanna.setup import LinearOpticalSetup\n",
    "from svetlanna.detector import Detector, DetectorProcessorClf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcf3be29-791b-48a3-946b-b300ea0e26e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna.visualization import show_stepwise_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d898096-f89a-4bb4-8bd2-b11d3b044c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna.clerk import Clerk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73440a60-e88a-49d7-81a2-d6a3bed3bf63",
   "metadata": {},
   "source": [
    "#### `src`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cbc8319-2f82-4979-889a-4efcc8466039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset of wavefronts\n",
    "from src.wf_datasets import DatasetOfWavefronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "688215a7-800b-4108-aaa6-807f98b1b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and evaluation loops\n",
    "from src.clf_loops import onn_train_clf, onn_validate_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dfb2cb-94cf-4e83-a079-0a6ec828a66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cea815ac-b473-4d58-a0d5-1253d9740a40",
   "metadata": {},
   "source": [
    "# Optical Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a43dea1-d35e-4916-9e97-b342a987d363",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Select the folder with results to load (TODO) </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "088ec2c4-7b5d-4da9-9639-cf3913bac03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_RESULTS = 'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5892df30-d236-4eb9-bb4e-e106b68d41b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_EXP = 'exp_21-06-2025_21-27'  # TODO: select experiment folder from the list above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e6182a7-efd9-49d7-9d50-e26cdb7802b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FOLDER = f'{DIR_RESULTS}/{SELECTED_EXP}'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85fc50be-7aed-4744-a7a0-328283ba11cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{RESULTS_FOLDER}/conditions.json') as json_file:\n",
    "    LOADED_VARIABLES = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "167255e4-2eac-45d4-954f-9aebc1b14f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wavelength': 0.000749481145,\n",
       " 'neuron_size': 0.00039722500685,\n",
       " 'mesh_size': [200, 200],\n",
       " 'use_apertures': False,\n",
       " 'aperture_size': [200, 200],\n",
       " 'detector_segment_size': 12,\n",
       " 'segments_order': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'train_val_seed': 34,\n",
       " 'torch_seed': 76,\n",
       " 'free_space_distance': 0.029979245800000002,\n",
       " 'num_diff_layers': 2,\n",
       " 'train_batch_size': 20,\n",
       " 'val_batch_size': 8,\n",
       " 'adam_lr': 0.001,\n",
       " 'number_of_epochs': 10}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOADED_VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a46e5e-6053-4e74-93eb-fb8e2c8f45a0",
   "metadata": {},
   "source": [
    "# 1. Simulation parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d815d886-8ffb-4a79-b488-6b207cd05b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_const = 299_792_458  # [m / s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e389f46c-f2ca-4204-a30f-c270e5987163",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_wavelength = LOADED_VARIABLES['wavelength']  # [m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "257fcf62-f897-4b81-af45-96326d47ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron size (square)\n",
    "neuron_size = LOADED_VARIABLES['neuron_size']  # [m]\n",
    "NEURON_SIZE = neuron_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19dc8771-a0e3-418b-9c0d-a725b21d12c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specified parameters:\n",
      "lambda = 749.481 um\n",
      "neuron size = 397.225 um\n"
     ]
    }
   ],
   "source": [
    "print('Specified parameters:')\n",
    "# uncomment next two lines!\n",
    "print(f'lambda = {working_wavelength * 1e6:.3f} um')\n",
    "print(f'neuron size = {neuron_size * 1e6:.3f} um')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6618b4ec-9fe2-45c7-8019-1f3b63c2e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an actual zone where weights will be updated during a training process\n",
    "ALL_SIZE = LOADED_VARIABLES['mesh_size']  # for example (100, 100) neurons\n",
    "USE_APERTURES = LOADED_VARIABLES['use_apertures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb111990-529e-4153-b585-ab0127bfc99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_APERTURES:\n",
    "    # if we will add apertures we must specify the aperture size here!\n",
    "    DETECTOR_SIZE = LOADED_VARIABLES['aperture_size']\n",
    "else:\n",
    "    DETECTOR_SIZE = ALL_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1da8d905-67e4-4df9-8686-ce14f1b71b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of neurons in simulation\n",
    "x_layer_nodes = ALL_SIZE[1]\n",
    "y_layer_nodes = ALL_SIZE[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd7d7f13-d150-48be-8e4c-c97ea588ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate physical size of each layer in [m]\n",
    "x_layer_size_m = x_layer_nodes * neuron_size  # [m]\n",
    "y_layer_size_m = y_layer_nodes * neuron_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37057e7b-8ba8-49d4-a9e3-c4b9ece0c7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size (in neurons): 200 x 200 = 40000\n",
      "Layer size (in cm): 7.944500137 x 7.944500137\n"
     ]
    }
   ],
   "source": [
    "print(f'Layer size (in neurons): {x_layer_nodes} x {y_layer_nodes} = {x_layer_nodes * y_layer_nodes}')\n",
    "print(f'Layer size (in cm): {x_layer_size_m * 1e2} x {y_layer_size_m * 1e2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d64da3-9611-4b74-84d0-a706f2c2e3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c3d95cc-633a-481a-bfa6-fe25a1d5b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation parameters for the rest of the notebook!\n",
    "\n",
    "SIM_PARAMS = SimulationParameters(\n",
    "    axes={\n",
    "        'W': torch.linspace(-x_layer_size_m / 2, x_layer_size_m / 2, x_layer_nodes),\n",
    "        'H': torch.linspace(-y_layer_size_m / 2, y_layer_size_m / 2, y_layer_nodes),\n",
    "        'wavelength': working_wavelength,  # monochromatic!\n",
    "    }\n",
    ")  # this is a custom object from our library `svetlanna`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d6f07c-1cb7-4b52-87c8-7c5306df2a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddbc9f3f-308d-4c58-b79c-de72e1eeff7b",
   "metadata": {},
   "source": [
    "# 2. Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18398b5-9ee7-470c-b2ef-bcd15b6f4768",
   "metadata": {},
   "source": [
    "## 2.1. [MNIST Dataset](https://www.kaggle.com/datasets/hojjatk/mnist-dataset)\n",
    "\n",
    "Here we load dataset of images but we need to transform them to Wavefronts in order to use them for DNN training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0de278d4-1f7a-4651-8fce-74c41567c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a directory for a dataset\n",
    "MNIST_DATA_FOLDER = './data'  # folder to store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1d740b2-dfd1-4bf3-a86c-6fb13a831df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN (images)\n",
    "mnist_train_ds = torchvision.datasets.MNIST(\n",
    "    root=MNIST_DATA_FOLDER,\n",
    "    train=True,  # for train dataset\n",
    "    download=True,\n",
    ")\n",
    "# TEST (images)\n",
    "mnist_test_ds = torchvision.datasets.MNIST(\n",
    "    root=MNIST_DATA_FOLDER,\n",
    "    train=False,  # for test dataset\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fb6dc4-3849-467c-957d-26617d8c5214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "208ca22f-13b4-4066-a850-1bd35776637b",
   "metadata": {},
   "source": [
    "## 2.2. Create Train and Test datasets of wavefronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c37007c-0731-4b58-9059-e2f2bb792b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select modulation type\n",
    "MODULATION_TYPE = 'amp'  # using ONLY amplitude to encode each picture in a Wavefront!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6297fd51-0bec-4b90-bf86-0346bc460f2e",
   "metadata": {},
   "source": [
    "### 2.2.1. Transformations of images to Wavefronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88113581-f819-4554-8d6a-db075f713a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_y = int(DETECTOR_SIZE[0] / 2)\n",
    "resize_x = int(DETECTOR_SIZE[1] / 2)  # shape for transforms.Resize\n",
    "\n",
    "# paddings along OY\n",
    "pad_top = int((y_layer_nodes - resize_y) / 2)\n",
    "pad_bottom = y_layer_nodes - pad_top - resize_y\n",
    "# paddings along OX\n",
    "pad_left = int((x_layer_nodes - resize_x) / 2)\n",
    "pad_right = x_layer_nodes - pad_left - resize_x  # params for transforms.Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47e20e55-53f7-4f92-95eb-3ef75d5dddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose all transforms!\n",
    "image_transform_for_ds = transforms.Compose(\n",
    "  [\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Resize(\n",
    "          size=(resize_y, resize_x),\n",
    "          interpolation=InterpolationMode.NEAREST,\n",
    "      ),\n",
    "      transforms.Pad(\n",
    "          padding=(\n",
    "              pad_left,  # left padding\n",
    "              pad_top,  # top padding\n",
    "              pad_right,  # right padding\n",
    "              pad_bottom  # bottom padding\n",
    "          ),\n",
    "          fill=0,\n",
    "      ),  # padding to match sizes!\n",
    "      ToWavefront(modulation_type=MODULATION_TYPE)  # <- select modulation type!!!\n",
    "  ]  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb08e9c-26e0-4241-b2b0-88ea4529e96b",
   "metadata": {},
   "source": [
    "### 2.2.2. Create Dataset objects for train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7309365a-2986-45e8-a259-97f378fcccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN dataset of WAVEFRONTS\n",
    "mnist_wf_train_ds = DatasetOfWavefronts(\n",
    "    init_ds=mnist_train_ds,  # dataset of images\n",
    "    transformations=image_transform_for_ds,  # image transformation\n",
    "    sim_params=SIM_PARAMS,  # simulation parameters\n",
    ")\n",
    "# TEST dataset of WAVEFRONTS\n",
    "mnist_wf_test_ds = DatasetOfWavefronts(\n",
    "    init_ds=mnist_test_ds,  # dataset of images\n",
    "    transformations=image_transform_for_ds,  # image transformation\n",
    "    sim_params=SIM_PARAMS,  # simulation parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ae7308-f611-4948-a9fd-afa66856dc09",
   "metadata": {},
   "source": [
    "# 3. Optical network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c72dbe6a-b8f5-42cd-9852-74f27fbe23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_DIFF_LAYERS = LOADED_VARIABLES['num_diff_layers']  # number of diffractive layers\n",
    "FREE_SPACE_DISTANCE = LOADED_VARIABLES['free_space_distance']  # [m] - distance between difractive layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de30d8bb-2854-4726-9757-e02fd1ed123e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between layers is 2.998 cm\n"
     ]
    }
   ],
   "source": [
    "print(f'Distance between layers is {FREE_SPACE_DISTANCE * 1e2:.3f} cm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "628a0c01-5dc2-46cb-9ee3-b6d1c0acaa26",
   "metadata": {},
   "source": [
    "## 3.1. Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c017b60c-cb2c-4707-800e-5dfd2770389c",
   "metadata": {},
   "source": [
    "### 3.1.1. Elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "572433d3-ddab-40ec-9fbf-974e0150f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PHASE = 2 * np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24e45194-9345-4287-af3e-27f8ebf6f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREESPACE_METHOD = 'AS'  # we use an angular spectrum method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "01fd8c37-cf07-4272-b2d5-b6b830ccc927",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_PHASES = torch.ones(NUM_OF_DIFF_LAYERS) * np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c8eff4-fd1a-41f2-b5df-056ff54edc2a",
   "metadata": {},
   "source": [
    "#### Functions that return single elements for further architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "22411824-c546-4721-99cb-1564445a4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKE A LOOK! CODE HERE IS READY\n",
    "def get_const_phase_layer(\n",
    "    sim_params: SimulationParameters,\n",
    "    value: float, \n",
    "    max_phase=2 * torch.pi\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns DiffractiveLayer with a constant phase mask.\n",
    "    \"\"\"\n",
    "    x_nodes, y_nodes = sim_params.axes_size(axs=('W', 'H'))\n",
    "\n",
    "    const_mask = torch.ones(size=(y_nodes, x_nodes)) * value\n",
    "    \n",
    "    return DiffractiveLayer(\n",
    "        simulation_parameters=sim_params,\n",
    "        mask=ConstrainedParameter(\n",
    "            const_mask,\n",
    "            min_value=0,\n",
    "            max_value=max_phase\n",
    "        ),  # HERE WE ARE USING CONSTRAINED PARAMETER! Phases are learnable!\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b103a40-895b-4915-bdb8-01cab2838c1d",
   "metadata": {},
   "source": [
    "### 3.1.2. List of Elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4e3cf49-5e7f-4fe1-81c9-dd90021c9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elements_list(\n",
    "    num_layers,\n",
    "    simulation_parameters,\n",
    "    freespace_method,\n",
    "    phase_values,\n",
    "    apertures=False,\n",
    "    aperture_size=(100, 100)\n",
    "):\n",
    "    \"\"\"\n",
    "    Composes a list of elements for the setup.\n",
    "    ...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_layers : int\n",
    "        Number of layers in the system.\n",
    "    simulation_parameters : SimulationParameters()\n",
    "        A simulation parameters for a task.\n",
    "    freespace_method : str\n",
    "        Propagation method for free spaces in a setup.\n",
    "    phase_values : torch.Tensor()\n",
    "        Torch tensor of phase values to generate constant masks for diffractive layers.\n",
    "        \n",
    "    apertures : bool\n",
    "        If True, than before each DiffractiveLayer (and detector) we add a square aperture.\n",
    "        Comment: there are strickt square apertures!\n",
    "    aperture_size : tuple\n",
    "        A size of apertures.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    elements_list : list(Element)\n",
    "        List of Elements for an optical setup.\n",
    "    \"\"\"\n",
    "    elements_list = []  # list of elements\n",
    "\n",
    "    # -------------------------------------------------- TODO AFTER THE LINE!\n",
    "    # -----------------------------------------------------------------------\n",
    "    \n",
    "    elements_list.append(\n",
    "        FreeSpace(\n",
    "            simulation_parameters,\n",
    "            distance=FREE_SPACE_DISTANCE,\n",
    "            method=freespace_method,\n",
    "        )\n",
    "    )  # first FreeSpace layer before first DiffractiveLayer\n",
    "\n",
    "    # several layers [Aperture + DiffractiveLayer + FreeSpace]\n",
    "    for ind_layer in range(num_layers):\n",
    "\n",
    "        # add square Aperture if needed\n",
    "        if apertures:\n",
    "            elements_list.append(\n",
    "                # your code...\n",
    "            )\n",
    "            \n",
    "        # add DiffractiveLayer (learnable phase mask) and FreeSpace\n",
    "        elements_list.append(\n",
    "            get_const_phase_layer(\n",
    "                simulation_parameters,\n",
    "                torch.pi,\n",
    "                max_phase=MAX_PHASE\n",
    "            )\n",
    "        )\n",
    "        elements_list.append(\n",
    "            FreeSpace(\n",
    "                simulation_parameters,\n",
    "                distance=FREE_SPACE_DISTANCE,\n",
    "                method=freespace_method,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # ----------------------------------------------------------- END OF TODO\n",
    "    # -----------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "    # -----------------------------------------------------------------------\n",
    "    # add add square Aperture before Detector\n",
    "    if apertures:\n",
    "        elements_list.append(\n",
    "            # your code...  # <-------------------------- HERE IS TODO TOO!!!\n",
    "        )\n",
    "    \n",
    "    # adding a Detector in the end of the system\n",
    "    # Detector returns torch.tensor of intencities (not a Wavefront - read documentation)\n",
    "    elements_list.append(\n",
    "        Detector(\n",
    "            simulation_parameters=simulation_parameters,\n",
    "            func='intensity'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return elements_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b12dba0-f5fb-461f-b724-a9ea57895765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "092f0c4c-6b3a-4d43-815e-eefc747922b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DIANA\\Downloads\\itmo_practice\\.venv\\Lib\\site-packages\\svetlanna\\elements\\free_space.py:150: UserWarning: Aliasing problems may occur in the AS method (x-axis). Consider reducing the distance.\n",
      "  warn(\n",
      "C:\\Users\\DIANA\\Downloads\\itmo_practice\\.venv\\Lib\\site-packages\\svetlanna\\elements\\free_space.py:155: UserWarning: Aliasing problems may occur in the AS method (y-axis). Consider reducing the distance.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "architecture_elements_list = get_elements_list(\n",
    "    num_layers=NUM_OF_DIFF_LAYERS,\n",
    "    simulation_parameters=SIM_PARAMS,\n",
    "    freespace_method=FREESPACE_METHOD,\n",
    "    phase_values=INIT_PHASES,\n",
    "    apertures=USE_APERTURES,\n",
    "    aperture_size=DETECTOR_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f2006774-6cd7-4c26-ac94-ea6ca05214b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in the system (including Detector): 6\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of elements in the system (including Detector): {len(architecture_elements_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a34cf91-1e75-4b23-a7d4-84ca094f0529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61958d45-f06e-4292-be5e-e0025dd1b2db",
   "metadata": {},
   "source": [
    "### 3.1.3. Compose `LinearOpticalSetup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "727a9d29-8b31-47e9-b0b0-fdae9d44c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_setup(simulation_parameters, num_layers=3, apertures=False):\n",
    "    \"\"\"\n",
    "    Returns an optical setup. Recreates all elements.\n",
    "    \"\"\"\n",
    "    elements_list = get_elements_list(\n",
    "        num_layers=num_layers,\n",
    "        simulation_parameters=SIM_PARAMS,\n",
    "        freespace_method=FREESPACE_METHOD,\n",
    "        phase_values=INIT_PHASES,\n",
    "        apertures=apertures,\n",
    "        aperture_size=DETECTOR_SIZE\n",
    "    )  # recreate a list of elements\n",
    "\n",
    "    return LinearOpticalSetup(elements=elements_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450c6c03-bd60-4a40-a557-ce3fb0ccd0c6",
   "metadata": {},
   "source": [
    "## 3.2. Detector processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91d1e9b5-8703-4201-8743-b54eac91da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_CLASSES = 10  # TODO: how many classes do we have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1dabde-317c-45c3-a9ee-4bffd403b5cb",
   "metadata": {},
   "source": [
    "### 3.2.1. Detector mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8c1e018-fb72-480e-b7a4-5eaf29145ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_segment_size = LOADED_VARIABLES['detector_segment_size']  # in neurons (int)\n",
    "detector_segment_size_m = detector_segment_size * NEURON_SIZE  # in [m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c92ff6e7-d778-4aeb-a6b3-a1d828977f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZONES_ORDER = LOADED_VARIABLES['segments_order']  # TODO: specify the order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eeb7d86b-ab1d-4575-a757-a8ee00f350dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTOR_MASK_LOADED = torch.load(f'{RESULTS_FOLDER}/detector_mask.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b79963c-18c5-4620-82cb-2485a986a1fd",
   "metadata": {},
   "source": [
    "### 3.2.2. Detector processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb2adcfd-788b-4939-8471-b87b95c31b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DetectorProcessorOzcanClf object\n",
    "DETECTOR_PROCESSOR = DetectorProcessorClf(\n",
    "    simulation_parameters=SIM_PARAMS,\n",
    "    num_classes=NUMBER_OF_CLASSES,\n",
    "    segmented_detector=DETECTOR_MASK_LOADED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec8806d-73da-4907-ae26-c3622d17553c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2651f63-1063-4b9b-bfb1-b3d0d543babc",
   "metadata": {},
   "source": [
    "#### To visualize detector zones (for further use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7b6bc396-cfbb-40a0-9bfe-e12987f9e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZONES_HIGHLIGHT_COLOR = 'w'\n",
    "ZONES_LW = 0.5\n",
    "selected_detector_mask = DETECTOR_PROCESSOR.segmented_detector.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd154079-4d24-4787-9304-df43fd2b7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zones_patches(detector_mask):\n",
    "    \"\"\"\n",
    "    Returns a list of patches to draw zones in final visualisation\n",
    "    \"\"\"\n",
    "    zones_patches = []\n",
    "\n",
    "    delta = 0.5\n",
    "    \n",
    "    for ind_class in range(NUMBER_OF_CLASSES):\n",
    "        idx_y, idx_x = (detector_mask == ind_class).nonzero(as_tuple=True)\n",
    "        \n",
    "        zone_rect = patches.Rectangle(\n",
    "            (idx_x[0] - delta, idx_y[0] - delta), \n",
    "            idx_x[-1] - idx_x[0] + 2 * delta, idx_y[-1] - idx_y[0] + 2 * delta, \n",
    "            linewidth=ZONES_LW, \n",
    "            edgecolor=ZONES_HIGHLIGHT_COLOR,\n",
    "            facecolor='none'\n",
    "        )\n",
    "        \n",
    "        zones_patches.append(zone_rect)\n",
    "\n",
    "    return zones_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ec106-878a-4475-bc01-e4b89c8a9280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b52ba22-b581-474e-b888-6cd3f0e757a3",
   "metadata": {},
   "source": [
    "# 4. Necessary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1f9c21c-bf3d-4a44-862d-8142fd6ae7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3dd9a8b-3e30-44df-8335-099fb140cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bs = LOADED_VARIABLES['train_batch_size']  # a batch size for training set\n",
    "val_bs = LOADED_VARIABLES['val_batch_size']\n",
    "\n",
    "test_bs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9f1f61-8c0a-46a1-b6f0-871babab56ad",
   "metadata": {},
   "source": [
    "#### Train/Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33ca736b-a938-416e-9362-40c22136c566",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split_seed = LOADED_VARIABLES['train_val_seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1eaacee1-7361-4d4c-83d6-815ccebaebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_wf_train_ds\n",
    "train_wf_ds, val_wf_ds = torch.utils.data.random_split(\n",
    "    dataset=mnist_wf_train_ds,\n",
    "    lengths=[55000, 5000],  # sizes from the article\n",
    "    generator=torch.Generator().manual_seed(train_val_split_seed)  # for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4df07d-b81c-4d05-9e25-1c0bb58f2eca",
   "metadata": {},
   "source": [
    "#### Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43c3fbef-5a00-4784-a5c8-85c47231890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wf_loader = torch.utils.data.DataLoader(\n",
    "    train_wf_ds,\n",
    "    batch_size=train_bs,\n",
    "    shuffle=True,\n",
    "    # num_workers=2,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "val_wf_loader = torch.utils.data.DataLoader(\n",
    "    val_wf_ds,\n",
    "    batch_size=val_bs,\n",
    "    shuffle=False,\n",
    "    # num_workers=2,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_wf_loader = torch.utils.data.DataLoader(\n",
    "    mnist_wf_test_ds,\n",
    "    batch_size=test_bs,\n",
    "    shuffle=False,\n",
    "    # num_workers=2,\n",
    "    drop_last=False,\n",
    ")  # data loader for a test MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74db11f-3f10-4d69-876d-9c4295a89438",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "390a425d-cff3-44ba-81f6-2fe467c52a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func_clf = nn.CrossEntropyLoss()\n",
    "loss_func_name = 'CE loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672b668-b6c1-49a5-bb38-610fad3dd7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb1247c6-9e1c-464c-8f9b-6330c56bfb52",
   "metadata": {},
   "source": [
    "# 5. Load model weights and estimate perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "652bda57-3625-4948-bbf1-59c7dd393107",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "89ed51a8-1d4a-4ca9-ae9f-aafa6899c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "FNAME = 'exp_zones'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e1682c76-1428-4715-9cf7-13d6d3f36e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def const_num_layer_exp_list(num_layers, fname):\n",
    "    selected_experiments = []\n",
    "    for file in os.listdir(DIR_RESULTS):      \n",
    "        \n",
    "        filename = os.fsdecode(file)\n",
    "        if fname in filename:\n",
    "            \n",
    "            if os.path.isdir(os.path.join(DIR_RESULTS, filename)):\n",
    "        \n",
    "                results_folder = f'{DIR_RESULTS}/{filename}'  \n",
    "                conditions_path = f'{results_folder}/conditions.json'\n",
    "        \n",
    "                if os.path.exists(conditions_path):\n",
    "                    with open(conditions_path) as json_file:\n",
    "                        loaded_var = json.load(json_file)\n",
    "        \n",
    "                    if 'num_diff_layers' in loaded_var.keys():\n",
    "                        if loaded_var['num_diff_layers'] == num_layers:\n",
    "                            selected_experiments.append(filename)\n",
    "    \n",
    "                    if 'number_of_diff_layers' in loaded_var.keys():\n",
    "                        if loaded_var['number_of_diff_layers'] == num_layers:\n",
    "                            selected_experiments.append(filename)        \n",
    "\n",
    "    return selected_experiments  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "45088113-76f8-4e2c-87ee-8e68219be0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_list = const_num_layer_exp_list(N_LAYERS, FNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "40710f97-3646-4404-969f-6e47d247091c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['exp_zones_23-06-2025_18-23',\n",
       " 'exp_zones_23-06-2025_18-47',\n",
       " 'exp_zones_23-06-2025_23-03']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42d51a5-11c3-48ee-94d9-b949552b2c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "53edf895-fc9c-457e-8f2c-f79b92bb6686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_22-06-2025_15-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation:  14%|█████████▏                                                         | 138/1000 [00:18<01:52,  7.64it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[176]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# LOAD WEIGHTS for the model\u001b[39;00m\n\u001b[32m     36\u001b[39m optical_setup_loaded.net.load_state_dict(\n\u001b[32m     37\u001b[39m     torch.load(model_path)\n\u001b[32m     38\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m _, _, test_accuracy = \u001b[43monn_validate_clf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptical_setup_loaded\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# optical network with loaded weights\u001b[39;49;00m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_wf_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# dataloader of training set\u001b[39;49;00m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdetector_proc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# detector processor\u001b[39;49;00m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_func_clf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_process\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# evaluate the model\u001b[39;00m\n\u001b[32m     49\u001b[39m test_acc_lst[exp] = test_accuracy * \u001b[32m100\u001b[39m   \u001b[38;5;66;03m#save accuracies\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\itmo_practice\\src\\clf_loops.py:149\u001b[39m, in \u001b[36monn_validate_clf\u001b[39m\u001b[34m(optical_net, wavefronts_dataloader, detector_processor_clf, loss_func, device, show_process)\u001b[39m\n\u001b[32m    147\u001b[39m detector_output  = optical_net(batch_wavefronts)\n\u001b[32m    148\u001b[39m \u001b[38;5;66;03m# process a detector image\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m batch_probas = \u001b[43mdetector_processor_clf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetector_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# calculate loss for a batch\u001b[39;00m\n\u001b[32m    151\u001b[39m loss = loss_func(batch_probas, batch_labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\itmo_practice\\.venv\\Lib\\site-packages\\svetlanna\\detector.py:350\u001b[39m, in \u001b[36mDetectorProcessorClf.batch_forward\u001b[39m\u001b[34m(self, batch_detector_data)\u001b[39m\n\u001b[32m    348\u001b[39m integrals_by_classes = torch.zeros(size=(batch_size, \u001b[38;5;28mself\u001b[39m.num_classes)).to(\u001b[38;5;28mself\u001b[39m.__device)\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ind_class \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_classes):\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m     integrals_by_classes[:, ind_class] = (\n\u001b[32m    351\u001b[39m             \u001b[38;5;28mself\u001b[39m.batch_zone_integral(batch_detector_data, ind_class) *\n\u001b[32m    352\u001b[39m             \u001b[38;5;28mself\u001b[39m.segments_weights[\u001b[32m0\u001b[39m, ind_class]\n\u001b[32m    353\u001b[39m     )\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m integrals_by_classes / torch.unsqueeze(integrals_by_classes.sum(dim=\u001b[32m1\u001b[39m), \u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "EPOCHS_LIM = 10\n",
    "test_acc_lst = {}\n",
    "\n",
    "for exp in exp_list:\n",
    "    print(exp)\n",
    "    \n",
    "    exp_path = f'{DIR_RESULTS}/{exp_zones}'\n",
    "\n",
    "    conditions_path = f'{exp_path}/conditions.json'\n",
    "    model_path = f'{exp_path}/optical_net.pth'\n",
    "    detector_mask_path = f'{exp_path}/detector_mask.pt'\n",
    "    losses_path = f'{exp_path}/training_curves.csv'\n",
    "\n",
    "    if os.path.exists(conditions_path):\n",
    "        with open(conditions_path) as json_file:\n",
    "            loaded_var = json.load(json_file)\n",
    "\n",
    "    if loaded_var['number_of_epochs'] >= EPOCHS_LIM:        \n",
    "\n",
    "        if os.path.exists(detector_mask_path):\n",
    "            # create a DetectorProcessorOzcanClf object\n",
    "            detector_proc = DetectorProcessorClf(\n",
    "                simulation_parameters=SIM_PARAMS,\n",
    "                num_classes=NUMBER_OF_CLASSES,\n",
    "                segmented_detector=torch.load(detector_mask_path),\n",
    "            )\n",
    "    \n",
    "        if os.path.exists(model_path):\n",
    "            # init setup to load weights\n",
    "            optical_setup_loaded = get_setup(\n",
    "                SIM_PARAMS, \n",
    "                N_LAYERS\n",
    "            )\n",
    "            \n",
    "            # LOAD WEIGHTS for the model\n",
    "            optical_setup_loaded.net.load_state_dict(\n",
    "                torch.load(model_path)\n",
    "            )\n",
    "    \n",
    "            _, _, test_accuracy = onn_validate_clf(\n",
    "                optical_setup_loaded.net,  # optical network with loaded weights\n",
    "                test_wf_loader,  # dataloader of training set\n",
    "                detector_proc,  # detector processor\n",
    "                loss_func_clf,\n",
    "                device=DEVICE,\n",
    "                show_process=True,\n",
    "            )  # evaluate the model\n",
    "    \n",
    "            test_acc_lst[exp] = test_accuracy * 100   #save accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3e4ec96c-0a18-4a0b-a613-ee577cd5e846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exp_23-06-2025_12-01': 63.660000000000004,\n",
       " 'exp_23-06-2025_12-42': 62.08,\n",
       " 'exp_23-06-2025_13-23': 63.44}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196f69c0-16d1-4942-8fa7-94dc545a72b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "515f1aad-4df2-4244-9c75-93cbc8444397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save experiment conditions (VARIABLES dictionary)\n",
    "with open(f'{DIR_RESULTS}/test_acc_{N_LAYERS:02d}-layers.json', 'w', encoding ='utf8') as json_file:\n",
    "    json.dump(test_acc_lst, json_file, ensure_ascii = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ca30c-6354-4f64-8eb1-b9132111d540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12a899b-4a90-4c81-8560-5e4d909890f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFUSSION MATRIXES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9625e554-655c-4242-a1dd-bc90f0211cee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m all_exp = []\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m.listdir(DIR_RESULTS):      \n\u001b[32m      5\u001b[39m         filename = os.fsdecode(file)\n\u001b[32m      6\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m os.path.isdir(os.path.join(DIR_RESULTS, filename)):\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "all_exp = []\n",
    "\n",
    "\n",
    "for file in os.listdir(DIR_RESULTS):      \n",
    "        filename = os.fsdecode(file)\n",
    "        if os.path.isdir(os.path.join(DIR_RESULTS, filename)):\n",
    "    \n",
    "            results_folder = f'{DIR_RESULTS}/{filename}'  \n",
    "            conditions_path = f'{results_folder}/conditions.json'\n",
    "    \n",
    "            if os.path.exists(conditions_path):\n",
    "                with open(conditions_path) as json_file:\n",
    "                    loaded_var = json.load(json_file)\n",
    "    \n",
    "                if 'number_of_epochs' in loaded_var.keys():\n",
    "                    if loaded_var['number_of_epochs'] >= 9:\n",
    "                        all_exp.append(filename)\n",
    "\n",
    "print(f'{len(all_exp)} experiments:')\n",
    "print(*all_exp, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69e7a2c-a479-4516-b65b-551a8bd4e11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0ca38ce3-1f1c-41bd-9bf0-1f6c68235e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(optical_setup_loaded, detector_processor):\n",
    "    targets_test_lst = []\n",
    "    preds_test_lst = []  # lists of targets and model predictioons\n",
    "    \n",
    "    # loop over the test dataset\n",
    "    for ind, (wavefront_this, target_this) in enumerate(tqdm(mnist_wf_test_ds)):\n",
    "        optical_setup_loaded.net.eval()\n",
    "        \n",
    "        batch_wavefronts = torch.unsqueeze(wavefront_this, 0)\n",
    "        batch_labels = torch.unsqueeze(torch.tensor(target_this), 0)  # to use forwards for batches\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            detector_output = optical_setup_loaded.net(batch_wavefronts)\n",
    "            # process a detector image\n",
    "            batch_probas = detector_processor.batch_forward(detector_output)\n",
    "    \n",
    "            for ind_in_batch in range(batch_labels.size()[0]):\n",
    "                label_this = batch_labels[ind_in_batch].item()  # true label\n",
    "                \n",
    "                targets_test_lst.append(label_this)\n",
    "                preds_test_lst.append(batch_probas[ind_in_batch].argmax().item())\n",
    "\n",
    "    confusion_matrix = torch.zeros(\n",
    "        size=(NUMBER_OF_CLASSES, NUMBER_OF_CLASSES),  # TODO: What is the size of the matrix?\n",
    "        dtype=torch.int32\n",
    "    )\n",
    "    \n",
    "    for ind in range(len(mnist_wf_test_ds)):\n",
    "        confusion_matrix[targets_test_lst[ind], preds_test_lst[ind]] += 1\n",
    "\n",
    "    return confusion_matrix         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "13c94423-ec6c-4f27-ad7e-311fd75fbbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_20-06-2025_22-22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [07:47<00:00, 21.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_21-06-2025_18-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████████████████████████▌                                  | 5532/10000 [04:18<03:28, 21.44it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[187]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# LOAD WEIGHTS for the model\u001b[39;00m\n\u001b[32m     38\u001b[39m optical_setup_loaded.net.load_state_dict(\n\u001b[32m     39\u001b[39m     torch.load(model_path)\n\u001b[32m     40\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m conf_mat = \u001b[43mpredict_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptical_setup_loaded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector_proc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m torch.save(conf_mat, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/confusion_matrix.pt\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[182]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mpredict_test\u001b[39m\u001b[34m(optical_setup_loaded, detector_processor)\u001b[39m\n\u001b[32m     10\u001b[39m batch_labels = torch.unsqueeze(torch.tensor(target_this), \u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# to use forwards for batches\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     detector_output = \u001b[43moptical_setup_loaded\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_wavefronts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# process a detector image\u001b[39;00m\n\u001b[32m     15\u001b[39m     batch_probas = detector_processor.batch_forward(detector_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\itmo_practice\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\itmo_practice\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\itmo_practice\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\itmo_practice\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\itmo_practice\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\itmo_practice\\.venv\\Lib\\site-packages\\svetlanna\\elements\\free_space.py:250\u001b[39m, in \u001b[36mFreeSpace.forward\u001b[39m\u001b[34m(self, incident_wavefront)\u001b[39m\n\u001b[32m    247\u001b[39m impulse_response_fft = \u001b[38;5;28mself\u001b[39m._impulse_response()\n\u001b[32m    249\u001b[39m \u001b[38;5;66;03m# Fourier image of output field\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m output_field_fft, _ = \u001b[43mtensor_dot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_field_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# example shape: (5, 'wavelength', 1, 'H', 'W')\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mb\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimpulse_response_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# example shape: ('wavelength', 'H', 'W')\u001b[39;49;00m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[43ma_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimulation_parameters\u001b[49m\u001b[43m.\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mb_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_calc_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreserve_a_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# check that the output has the input shape\u001b[39;49;00m\n\u001b[32m    256\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# example output shape: (5, 'wavelength', 1, 'H', 'W')\u001b[39;00m\n\u001b[32m    258\u001b[39m output_field = torch.fft.ifft2(\n\u001b[32m    259\u001b[39m     output_field_fft,\n\u001b[32m    260\u001b[39m     dim=(\u001b[38;5;28mself\u001b[39m._h_index, \u001b[38;5;28mself\u001b[39m._w_index)\n\u001b[32m    261\u001b[39m )\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output_field\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\itmo_practice\\.venv\\Lib\\site-packages\\svetlanna\\axes_math.py:279\u001b[39m, in \u001b[36mtensor_dot\u001b[39m\u001b[34m(a, b, a_axis, b_axis, preserve_a_axis)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(a):\n\u001b[32m    278\u001b[39m     a = cast(torch.Tensor, a)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     a = \u001b[43mcast_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_axes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(b):\n\u001b[32m    281\u001b[39m     b = cast(torch.Tensor, b)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\itmo_practice\\.venv\\Lib\\site-packages\\svetlanna\\axes_math.py:153\u001b[39m, in \u001b[36mcast_tensor\u001b[39m\u001b[34m(a, axes, new_axes)\u001b[39m\n\u001b[32m    150\u001b[39m a = a[_append_slice(axes, new_axes)]\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# swap required axes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_swaps\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxes_indices\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    154\u001b[39m     a = a.swapaxes(i, j)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for exp in all_exp:\n",
    "    print(exp)\n",
    "    \n",
    "    exp_path = f'{DIR_RESULTS}/{exp}'\n",
    "\n",
    "    conditions_path = f'{exp_path}/conditions.json'\n",
    "    model_path = f'{exp_path}/optical_net.pth'\n",
    "    detector_mask_path = f'{exp_path}/detector_mask.pt'\n",
    "    losses_path = f'{exp_path}/training_curves.csv'\n",
    "\n",
    "            \n",
    "    if os.path.exists(conditions_path):\n",
    "        with open(conditions_path) as json_file:\n",
    "            loaded_var = json.load(json_file)\n",
    "    \n",
    "        if 'num_diff_layers' in loaded_var.keys():\n",
    "            num_layers = loaded_var['num_diff_layers']\n",
    "                    \n",
    "        if 'number_of_diff_layers' in loaded_var.keys():\n",
    "            num_layers = loaded_var['number_of_diff_layers']\n",
    "  \n",
    "    if os.path.exists(detector_mask_path):\n",
    "        # create a DetectorProcessorOzcanClf object\n",
    "        detector_proc = DetectorProcessorClf(\n",
    "            simulation_parameters=SIM_PARAMS,\n",
    "            num_classes=NUMBER_OF_CLASSES,\n",
    "            segmented_detector=torch.load(detector_mask_path),\n",
    "        )\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        # init setup to load weights\n",
    "        optical_setup_loaded = get_setup(\n",
    "            SIM_PARAMS, \n",
    "            num_layers,\n",
    "        )\n",
    "            \n",
    "        # LOAD WEIGHTS for the model\n",
    "        optical_setup_loaded.net.load_state_dict(\n",
    "            torch.load(model_path)\n",
    "        )\n",
    "\n",
    "        conf_mat = predict_test(optical_setup_loaded, detector_proc)\n",
    "\n",
    "        torch.save(conf_mat, f'{exp_path}/confusion_matrix.pt')\n",
    "  \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9489618-67d3-4035-8634-8cf5dff3aa8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ed6d3f-0449-4666-8fe8-d32cf11eff0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08acc0e1-20ed-403a-a2c1-4baecbc709aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ecb3122-ca66-4b28-be8c-7a3bf6d8fb71",
   "metadata": {},
   "source": [
    "## 5.1. Loading of saved results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342eab76-fa52-48f7-a08c-be962e58ef9d",
   "metadata": {},
   "source": [
    "### 5.1.1. Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec8a714-5da7-4a6c-a91a-b05a99902c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_data = np.genfromtxt(\n",
    "    f'{RESULTS_FOLDER}/training_curves.csv',\n",
    "    delimiter=','\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b660e1-c997-438f-bcdd-d28e10ae995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = LOADED_VARIABLES['number_of_epochs']\n",
    "(train_epochs_losses, val_epochs_losses, train_epochs_acc, val_epochs_acc) = losses_data[1:, :].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628fab74-a031-49a8-abe5-1d2d99f7631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curves plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "axs[0].plot(range(1, NUM_EPOCHS + 1), np.array(train_epochs_losses), label='train')\n",
    "axs[0].plot(range(1, NUM_EPOCHS + 1), np.array(val_epochs_losses), linestyle='dashed', label='validation')\n",
    "\n",
    "axs[1].plot(range(1, NUM_EPOCHS + 1), train_epochs_acc, label='train')\n",
    "axs[1].plot(range(1, NUM_EPOCHS + 1), val_epochs_acc, linestyle='dashed', label='validation')\n",
    "\n",
    "axs[0].set_ylabel(loss_func_name)\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30cbf38-77de-4df0-8094-25be5a19a47e",
   "metadata": {},
   "source": [
    "### 5.1.2. Weights of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de870579-4415-4018-a3f4-ed7fa1d04f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init setup to load weights\n",
    "optical_setup_loaded = get_setup(SIM_PARAMS, LOADED_VARIABLES['use_apertures'])\n",
    "# LOAD WEIGHTS for the model\n",
    "optical_setup_loaded.net.load_state_dict(torch.load(f'{RESULTS_FOLDER}/optical_net.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d7330d-a12c-4078-acc7-352cfdfe1df8",
   "metadata": {},
   "source": [
    "### 5.1.3. Trained phase masks visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11683040-3e27-4377-959c-bea12a776875",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = NUM_OF_DIFF_LAYERS  # number of columns for DiffractiveLayer's masks visualization\n",
    "n_rows = 1\n",
    "\n",
    "# plot wavefronts phase\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 3, n_rows * 3.2))\n",
    "ind_diff_layer = 0\n",
    "\n",
    "cmap = 'gist_stern'  # 'gist_stern' 'rainbow'\n",
    "\n",
    "for ind_layer, layer in enumerate(optical_setup_loaded.net):\n",
    "    if isinstance(layer, DiffractiveLayer):  # plot masks for Diffractive layers\n",
    "        if n_rows > 1:\n",
    "            ax_this = axs[ind_diff_layer // n_cols][ind_diff_layer % n_cols]\n",
    "        else:\n",
    "            ax_this = axs[ind_diff_layer % n_cols]\n",
    "\n",
    "        ax_this.set_title(f'{ind_diff_layer + 1}. DiffractiveLayer')\n",
    "\n",
    "        trained_mask = layer.mask.detach()\n",
    "        \n",
    "        ax_this.imshow(         \n",
    "            trained_mask, cmap=cmap,\n",
    "            vmin=0, vmax=MAX_PHASE\n",
    "        )\n",
    "        ind_diff_layer += 1\n",
    "\n",
    "        # select only a part within apertures!\n",
    "        # x_frame = (x_layer_nodes - DETECTOR_SIZE[1]) / 2\n",
    "        # y_frame = (y_layer_nodes - DETECTOR_SIZE[0]) / 2\n",
    "        # ax_this.set_xlim([x_frame, x_layer_nodes - x_frame])\n",
    "        # ax_this.set_ylim([y_frame, y_layer_nodes - y_frame])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6a8c7-c74a-414a-923d-4f080708b8b5",
   "metadata": {},
   "source": [
    "## 5.2. Calculate metrics on test set for the loaded model\n",
    "\n",
    "Checking if the loaded model works correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98333cf9-832f-46ac-8bfa-fef032846a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses_1, _, test_accuracy_1 = onn_validate_clf(\n",
    "    optical_setup_loaded.net,  # optical network with loaded weights\n",
    "    test_wf_loader,  # dataloader of training set\n",
    "    DETECTOR_PROCESSOR,  # detector processor\n",
    "    loss_func_clf,\n",
    "    device=DEVICE,\n",
    "    show_process=True,\n",
    ")  # evaluate the model\n",
    "\n",
    "print(\n",
    "    'Results after training on TEST set:\\n' + \n",
    "    f'\\t{loss_func_name} : {np.mean(test_losses_1):.6f}\\n' +\n",
    "    f'\\tAccuracy : {(test_accuracy_1 * 100):>0.1f} %'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ced0a-7948-4685-bd4e-57ef9e58adfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f47740db-90ff-4b2f-a362-7731a460e768",
   "metadata": {},
   "source": [
    "## 5.3. Example of classification (propagation through the setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba54cc2-d8df-4df5-8aed-08c4f0bd89be",
   "metadata": {},
   "source": [
    "### 5.3.1. Select a sample to propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc4e7e-cfb7-4ed3-9caf-87bc39b7ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot an image\n",
    "# '1' - 3214, good\n",
    "# '4' - 6152, good\n",
    "# '6' - 123, good\n",
    "# '8' - 128, good\n",
    "# '0' - 3, good\n",
    "ind_test = 123\n",
    "cmap = 'hot'\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(2 * 3, 3))\n",
    "\n",
    "test_wavefront, test_target = mnist_wf_test_ds[ind_test]\n",
    "\n",
    "axs[0].set_title(f'intensity (id={ind_test})')\n",
    "axs[0].imshow(test_wavefront.intensity, cmap=cmap)\n",
    "\n",
    "axs[1].set_title(f'phase')\n",
    "axs[1].imshow(\n",
    "    test_wavefront.phase, cmap=cmap,\n",
    "    vmin=0, vmax=2 * torch.pi\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f725f858-61f1-4157-978e-a71403c67701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# propagation of the example through the trained network\n",
    "setup_scheme, test_wavefronts = optical_setup_loaded.stepwise_forward(test_wavefront)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dc20fc-647b-4434-9603-45ff80c09059",
   "metadata": {},
   "source": [
    "### 5.3.2. Detector picture (enlarged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c616ff93-51d4-412d-8475-4cb33954aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure with subplots\n",
    "fig, ax_this = plt.subplots(1, 1, figsize=(3, 3.2))\n",
    "\n",
    "# Detector output (not a wavefront!)\n",
    "ax_this.set_title('Detector Intensity')\n",
    "ax_this.imshow(\n",
    "    test_wavefronts[-1].detach().numpy(), cmap='hot',\n",
    "    # vmin=0, vmax=1  # uncomment to make the same limits\n",
    ")\n",
    "\n",
    "for zone in get_zones_patches(DETECTOR_MASK_LOADED):\n",
    "    # add zone's patches to the axis\n",
    "    ax_this.add_patch(zone)\n",
    "\n",
    "# select only a part within apertures! uncomment if needed\n",
    "# x_frame = (x_layer_nodes - DETECTOR_SIZE[1]) / 2\n",
    "# y_frame = (y_layer_nodes - DETECTOR_SIZE[0]) / 2\n",
    "\n",
    "# plt.axis([x_frame, x_layer_nodes - x_frame, y_layer_nodes - y_frame, y_frame])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392dd721-c8de-4e54-bf55-931c498c4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities of an example classification\n",
    "test_probas = DETECTOR_PROCESSOR.forward(test_wavefronts[-1])\n",
    "# Comment: forward() method is from DetectorProcessorClf\n",
    "#          p_i = I(detector_i) / sum_j(I(detector_j))\n",
    "# Comment: It's another output than for batch_forward, that was used during training!\n",
    "\n",
    "assert np.isclose(test_probas.sum().item(), 1)\n",
    "\n",
    "for label, prob in enumerate(test_probas[0]):\n",
    "    print(f'{label} : {prob * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a24a10-101d-4862-b731-94a6470a0fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5592d4b4-0ea4-456b-9d65-5f56e915ee6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
